mode: 'eval'
env_name: 'LunarLander-v2'
model_name: 'dlqn1d'
num_episodes: 10000
max_timesteps: 1000
reward_logging_frequency: 100

model_args: {
  num_actions: 4,
  sequence_length: 1,
  hidden_sizes: [ 8, 64, 128, 256, 512 ],
  dropout: 0.1
}

activation_args: {
  activation: "relu"
}

agent_args: {
  gamma: 0.99,
  epsilon: 0.01,
  min_epsilon: 0.01,
  num_actions: 4,
  memory_buffer_size: 1048576,
  target_model_update_rate: 64,
  policy_model_update_rate: 4,
  min_lr: 1e-5,
  model_backup_frequency: 10000,
  batch_size: 64,
  epsilon_decay_rate: 0.995,
  epsilon_decay_frequency: 2048,
  apply_norm: "none",
  apply_norm_to: [ "none" ],
  tau: 0.83,
  force_terminal_state_selection_prob: 0.7
}

optimizer_args: {
  optimizer: "adam",
  lr: 0.001,
  weight_decay: 0.01,
}

lr_scheduler_args: {
  "scheduler": "step_lr",
  "step_size": 128,
  "gamma": 0.999,
}

loss_function_args: {
  "loss_function": "huber_loss"
}

device: 'cpu'
