<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: rlpack.dqn.dqn_agent.DqnAgent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-static-methods">Static Private Member Functions</a> &#124;
<a href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">rlpack.dqn.dqn_agent.DqnAgent Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Inheritance diagram for rlpack.dqn.dqn_agent.DqnAgent:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
 <div class="center">
  <img src="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.png" usemap="#rlpack.dqn.dqn_5Fagent.DqnAgent_map" alt=""/>
  <map id="rlpack.dqn.dqn_5Fagent.DqnAgent_map" name="rlpack.dqn.dqn_5Fagent.DqnAgent_map">
<area href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html" alt="rlpack.utils.base.agent.Agent" shape="rect" coords="0,56,192,80"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a2b9fa686b41a52da69afea373ee2272d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a2b9fa686b41a52da69afea373ee2272d">__init__</a> (self, pytorch.nn.Module target_model, pytorch.nn.Module policy_model, pytorch.optim.Optimizer optimizer, Union[LRScheduler, None] lr_scheduler, LossFunction loss_function, float gamma, float epsilon, float min_epsilon, float epsilon_decay_rate, int epsilon_decay_frequency, int memory_buffer_size, int target_model_update_rate, int policy_model_update_rate, int model_backup_frequency, float lr_threshold, int batch_size, int num_actions, str save_path, str device=&quot;cpu&quot;, Optional[Dict[str, Any]] prioritization_params=None, float force_terminal_state_selection_prob=0.0, float tau=1.0, int apply_norm=-1, int apply_norm_to=-1, float eps_for_norm=5e-12, int p_for_norm=2, int dim_for_norm=0)</td></tr>
<tr class="separator:a2b9fa686b41a52da69afea373ee2272d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adfd9b38d7e3b4f55eb7f857b0285ae0c"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#adfd9b38d7e3b4f55eb7f857b0285ae0c">load</a> (self, Optional[str] custom_name_suffix=None)</td></tr>
<tr class="separator:adfd9b38d7e3b4f55eb7f857b0285ae0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38ee1487797979a2ca7ad4db304d27b4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a38ee1487797979a2ca7ad4db304d27b4">policy</a> (self, Union[ndarray, pytorch.Tensor, List[float]] state_current)</td></tr>
<tr class="separator:a38ee1487797979a2ca7ad4db304d27b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabbebafa737394e23228307873976a6b"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#aabbebafa737394e23228307873976a6b">save</a> (self, Optional[str] custom_name_suffix=None)</td></tr>
<tr class="separator:aabbebafa737394e23228307873976a6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61291ffa28e7056e977f8b24259a1008"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a61291ffa28e7056e977f8b24259a1008">temporal_difference</a> (self, pytorch.Tensor rewards, pytorch.Tensor q_values, pytorch.Tensor dones)</td></tr>
<tr class="separator:a61291ffa28e7056e977f8b24259a1008"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f91cd9fcd61a59fd87bd6dde3cf5c8b"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a5f91cd9fcd61a59fd87bd6dde3cf5c8b">train</a> (self, Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]] state_current, Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]] state_next, Union[int, float] reward, Union[int, float] action, Union[bool, int] done, Optional[Union[pytorch.Tensor, np.ndarray, float]] priority=1.0, Optional[Union[pytorch.Tensor, np.ndarray, float]] probability=1.0, Optional[Union[pytorch.Tensor, np.ndarray, float]] weight=1.0)</td></tr>
<tr class="separator:a5f91cd9fcd61a59fd87bd6dde3cf5c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">rlpack.utils.base.agent.Agent</a></td></tr>
<tr class="memitem:accaa47a12b6f65fee88824d3018b8c8e inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Dict[str, Any]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#accaa47a12b6f65fee88824d3018b8c8e">__getstate__</a> (self)</td></tr>
<tr class="separator:accaa47a12b6f65fee88824d3018b8c8e inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a364aa41c59de32a363b2e4c241dfef3f inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a364aa41c59de32a363b2e4c241dfef3f">__init__</a> (self)</td></tr>
<tr class="separator:a364aa41c59de32a363b2e4c241dfef3f inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04286fc7bb9ca0a64bce5eaf3620db7b inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a04286fc7bb9ca0a64bce5eaf3620db7b">__setstate__</a> (self, Dict[str, Any] state)</td></tr>
<tr class="separator:a04286fc7bb9ca0a64bce5eaf3620db7b inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac493d40ce8bd5562822a01aba0265181 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ac493d40ce8bd5562822a01aba0265181">load</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:ac493d40ce8bd5562822a01aba0265181 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5e3e4db83e80ef7bb422a148cd3e1f6 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ab5e3e4db83e80ef7bb422a148cd3e1f6">policy</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:ab5e3e4db83e80ef7bb422a148cd3e1f6 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa61ea2248a43a7bbc9b7c9ab7c240564 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#aa61ea2248a43a7bbc9b7c9ab7c240564">save</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:aa61ea2248a43a7bbc9b7c9ab7c240564 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38c313422ef6c713efd5ef9301b35111 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a38c313422ef6c713efd5ef9301b35111">train</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:a38c313422ef6c713efd5ef9301b35111 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:add872066ef9a8e4f43bbcb765fb66103"><td class="memItemLeft" align="right" valign="top"><a id="add872066ef9a8e4f43bbcb765fb66103" name="add872066ef9a8e4f43bbcb765fb66103"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>apply_norm</b></td></tr>
<tr class="separator:add872066ef9a8e4f43bbcb765fb66103"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65bbfa35c0a6c51cc2d7500a118aff5e"><td class="memItemLeft" align="right" valign="top"><a id="a65bbfa35c0a6c51cc2d7500a118aff5e" name="a65bbfa35c0a6c51cc2d7500a118aff5e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>apply_norm_to</b></td></tr>
<tr class="separator:a65bbfa35c0a6c51cc2d7500a118aff5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0dcef173b93afb6eeb2c2f2bbed8fe7d"><td class="memItemLeft" align="right" valign="top"><a id="a0dcef173b93afb6eeb2c2f2bbed8fe7d" name="a0dcef173b93afb6eeb2c2f2bbed8fe7d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>batch_size</b></td></tr>
<tr class="separator:a0dcef173b93afb6eeb2c2f2bbed8fe7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa24c4cde1b3c86793aa0c163975f7e46"><td class="memItemLeft" align="right" valign="top"><a id="aa24c4cde1b3c86793aa0c163975f7e46" name="aa24c4cde1b3c86793aa0c163975f7e46"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="separator:aa24c4cde1b3c86793aa0c163975f7e46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab587b11f42305490ece52cb5683cee6d"><td class="memItemLeft" align="right" valign="top"><a id="ab587b11f42305490ece52cb5683cee6d" name="ab587b11f42305490ece52cb5683cee6d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>dim_for_norm</b></td></tr>
<tr class="separator:ab587b11f42305490ece52cb5683cee6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2f3ca72d4ac525130ddab5c3ab08f3c"><td class="memItemLeft" align="right" valign="top"><a id="ac2f3ca72d4ac525130ddab5c3ab08f3c" name="ac2f3ca72d4ac525130ddab5c3ab08f3c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>eps_for_norm</b></td></tr>
<tr class="separator:ac2f3ca72d4ac525130ddab5c3ab08f3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c8074b05362bbcf9c2518938e43ce24"><td class="memItemLeft" align="right" valign="top"><a id="a4c8074b05362bbcf9c2518938e43ce24" name="a4c8074b05362bbcf9c2518938e43ce24"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>epsilon</b></td></tr>
<tr class="separator:a4c8074b05362bbcf9c2518938e43ce24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9c0ee89d768180a64862811f202d57f"><td class="memItemLeft" align="right" valign="top"><a id="ad9c0ee89d768180a64862811f202d57f" name="ad9c0ee89d768180a64862811f202d57f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>epsilon_decay_frequency</b></td></tr>
<tr class="separator:ad9c0ee89d768180a64862811f202d57f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32122333d34d04772bc5a5882923c8fe"><td class="memItemLeft" align="right" valign="top"><a id="a32122333d34d04772bc5a5882923c8fe" name="a32122333d34d04772bc5a5882923c8fe"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>epsilon_decay_rate</b></td></tr>
<tr class="separator:a32122333d34d04772bc5a5882923c8fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8dae08b557f3cd26031efe5abc65225"><td class="memItemLeft" align="right" valign="top"><a id="ad8dae08b557f3cd26031efe5abc65225" name="ad8dae08b557f3cd26031efe5abc65225"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>force_terminal_state_selection_prob</b></td></tr>
<tr class="separator:ad8dae08b557f3cd26031efe5abc65225"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8599ea966ed65fd8cb9a1731b0b8cee6"><td class="memItemLeft" align="right" valign="top"><a id="a8599ea966ed65fd8cb9a1731b0b8cee6" name="a8599ea966ed65fd8cb9a1731b0b8cee6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>gamma</b></td></tr>
<tr class="separator:a8599ea966ed65fd8cb9a1731b0b8cee6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16b0b31d7e47cf9c56f09cf2b1c6c733"><td class="memItemLeft" align="right" valign="top"><a id="a16b0b31d7e47cf9c56f09cf2b1c6c733" name="a16b0b31d7e47cf9c56f09cf2b1c6c733"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss_function</b></td></tr>
<tr class="separator:a16b0b31d7e47cf9c56f09cf2b1c6c733"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac449f6bbe49ee6fb8005bb232b653147"><td class="memItemLeft" align="right" valign="top"><a id="ac449f6bbe49ee6fb8005bb232b653147" name="ac449f6bbe49ee6fb8005bb232b653147"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>lr_scheduler</b></td></tr>
<tr class="separator:ac449f6bbe49ee6fb8005bb232b653147"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9855b6ae475270ab00627e7f9669adc2"><td class="memItemLeft" align="right" valign="top"><a id="a9855b6ae475270ab00627e7f9669adc2" name="a9855b6ae475270ab00627e7f9669adc2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>memory</b></td></tr>
<tr class="separator:a9855b6ae475270ab00627e7f9669adc2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4dd2c4a11614357b3215c406c97b90f"><td class="memItemLeft" align="right" valign="top"><a id="ac4dd2c4a11614357b3215c406c97b90f" name="ac4dd2c4a11614357b3215c406c97b90f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>memory_buffer_size</b></td></tr>
<tr class="separator:ac4dd2c4a11614357b3215c406c97b90f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8983773caff8991f5a1429d44fbdd974"><td class="memItemLeft" align="right" valign="top"><a id="a8983773caff8991f5a1429d44fbdd974" name="a8983773caff8991f5a1429d44fbdd974"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>min_epsilon</b></td></tr>
<tr class="separator:a8983773caff8991f5a1429d44fbdd974"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeee15780934b3e56052e77ce0ca0134c"><td class="memItemLeft" align="right" valign="top"><a id="aeee15780934b3e56052e77ce0ca0134c" name="aeee15780934b3e56052e77ce0ca0134c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>min_lr</b></td></tr>
<tr class="separator:aeee15780934b3e56052e77ce0ca0134c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a529efa431f3721f5595929a9b69c7fb1"><td class="memItemLeft" align="right" valign="top"><a id="a529efa431f3721f5595929a9b69c7fb1" name="a529efa431f3721f5595929a9b69c7fb1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>model_backup_frequency</b></td></tr>
<tr class="separator:a529efa431f3721f5595929a9b69c7fb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a297deb3d774deb419006e7fbf8aff7a5"><td class="memItemLeft" align="right" valign="top"><a id="a297deb3d774deb419006e7fbf8aff7a5" name="a297deb3d774deb419006e7fbf8aff7a5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>normalization</b></td></tr>
<tr class="separator:a297deb3d774deb419006e7fbf8aff7a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a6cabaa890c0f28fbedbce96869a500"><td class="memItemLeft" align="right" valign="top"><a id="a5a6cabaa890c0f28fbedbce96869a500" name="a5a6cabaa890c0f28fbedbce96869a500"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>num_actions</b></td></tr>
<tr class="separator:a5a6cabaa890c0f28fbedbce96869a500"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc53e8b41e11abbadb20139877910c7"><td class="memItemLeft" align="right" valign="top"><a id="a5bc53e8b41e11abbadb20139877910c7" name="a5bc53e8b41e11abbadb20139877910c7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>optimizer</b></td></tr>
<tr class="separator:a5bc53e8b41e11abbadb20139877910c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e82951d76c6c5db30d23c13d5286981"><td class="memItemLeft" align="right" valign="top"><a id="a9e82951d76c6c5db30d23c13d5286981" name="a9e82951d76c6c5db30d23c13d5286981"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>p_for_norm</b></td></tr>
<tr class="separator:a9e82951d76c6c5db30d23c13d5286981"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8adcc90bb59c4bd0f1a153f89c3116d"><td class="memItemLeft" align="right" valign="top"><a id="aa8adcc90bb59c4bd0f1a153f89c3116d" name="aa8adcc90bb59c4bd0f1a153f89c3116d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>policy_model</b></td></tr>
<tr class="separator:aa8adcc90bb59c4bd0f1a153f89c3116d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37d7273d3b9e856c3858c34b6034c770"><td class="memItemLeft" align="right" valign="top"><a id="a37d7273d3b9e856c3858c34b6034c770" name="a37d7273d3b9e856c3858c34b6034c770"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>policy_model_update_rate</b></td></tr>
<tr class="separator:a37d7273d3b9e856c3858c34b6034c770"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecf463bba48c45f10bdf5ba8d8d978bc"><td class="memItemLeft" align="right" valign="top"><a id="aecf463bba48c45f10bdf5ba8d8d978bc" name="aecf463bba48c45f10bdf5ba8d8d978bc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>prioritization_params</b></td></tr>
<tr class="separator:aecf463bba48c45f10bdf5ba8d8d978bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411ecb8f76f5ee42352474cad744bf03"><td class="memItemLeft" align="right" valign="top"><a id="a411ecb8f76f5ee42352474cad744bf03" name="a411ecb8f76f5ee42352474cad744bf03"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>prioritization_strategy_code</b></td></tr>
<tr class="separator:a411ecb8f76f5ee42352474cad744bf03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ebb3729ba7414e487b839ffa2198f7a"><td class="memItemLeft" align="right" valign="top"><a id="a7ebb3729ba7414e487b839ffa2198f7a" name="a7ebb3729ba7414e487b839ffa2198f7a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>save_path</b></td></tr>
<tr class="separator:a7ebb3729ba7414e487b839ffa2198f7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ba7d14eb2a55b43b904c7f89ff37148"><td class="memItemLeft" align="right" valign="top"><a id="a1ba7d14eb2a55b43b904c7f89ff37148" name="a1ba7d14eb2a55b43b904c7f89ff37148"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>step_counter</b></td></tr>
<tr class="separator:a1ba7d14eb2a55b43b904c7f89ff37148"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba41d3fc796d221f77fc8e501b01e86e"><td class="memItemLeft" align="right" valign="top"><a id="aba41d3fc796d221f77fc8e501b01e86e" name="aba41d3fc796d221f77fc8e501b01e86e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>target_model</b></td></tr>
<tr class="separator:aba41d3fc796d221f77fc8e501b01e86e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2f64d463f70a32e203e79d069722c84"><td class="memItemLeft" align="right" valign="top"><a id="ac2f64d463f70a32e203e79d069722c84" name="ac2f64d463f70a32e203e79d069722c84"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>target_model_update_rate</b></td></tr>
<tr class="separator:ac2f64d463f70a32e203e79d069722c84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a641f2954d39a51703ce14d3490ffd5"><td class="memItemLeft" align="right" valign="top"><a id="a2a641f2954d39a51703ce14d3490ffd5" name="a2a641f2954d39a51703ce14d3490ffd5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>tau</b></td></tr>
<tr class="separator:a2a641f2954d39a51703ce14d3490ffd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">rlpack.utils.base.agent.Agent</a></td></tr>
<tr class="memitem:aa4b5b7a651697524896373ca24d0ba16 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="aa4b5b7a651697524896373ca24d0ba16" name="aa4b5b7a651697524896373ca24d0ba16"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>advantage_norm_codes</b></td></tr>
<tr class="separator:aa4b5b7a651697524896373ca24d0ba16 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3ce395269c69c095865fee40818db2e inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="ab3ce395269c69c095865fee40818db2e" name="ab3ce395269c69c095865fee40818db2e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss</b></td></tr>
<tr class="separator:ab3ce395269c69c095865fee40818db2e inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4084a4f3b18536d1c0a871b151971bd7 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="a4084a4f3b18536d1c0a871b151971bd7" name="a4084a4f3b18536d1c0a871b151971bd7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>reward_norm_codes</b></td></tr>
<tr class="separator:a4084a4f3b18536d1c0a871b151971bd7 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4779a7186807d901e8ffc8cc8951527a inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="a4779a7186807d901e8ffc8cc8951527a" name="a4779a7186807d901e8ffc8cc8951527a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>save_path</b></td></tr>
<tr class="separator:a4779a7186807d901e8ffc8cc8951527a inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0500457a682bad272e8e28b9a475fcb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="ae0500457a682bad272e8e28b9a475fcb" name="ae0500457a682bad272e8e28b9a475fcb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>state_norm_codes</b></td></tr>
<tr class="separator:ae0500457a682bad272e8e28b9a475fcb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa672333065b88d4734b58ad8bc1433eb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="aa672333065b88d4734b58ad8bc1433eb" name="aa672333065b88d4734b58ad8bc1433eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>td_norm_codes</b></td></tr>
<tr class="separator:aa672333065b88d4734b58ad8bc1433eb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:a1d6e4cd8aee12060b401eee2c14f338b"><td class="memItemLeft" align="right" valign="top"><a id="a1d6e4cd8aee12060b401eee2c14f338b" name="a1d6e4cd8aee12060b401eee2c14f338b"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__anneal_alpha</b> (self)</td></tr>
<tr class="separator:a1d6e4cd8aee12060b401eee2c14f338b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cf0a7a1b3f7eb23870d59f8567c4d62"><td class="memItemLeft" align="right" valign="top"><a id="a6cf0a7a1b3f7eb23870d59f8567c4d62" name="a6cf0a7a1b3f7eb23870d59f8567c4d62"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__anneal_beta</b> (self)</td></tr>
<tr class="separator:a6cf0a7a1b3f7eb23870d59f8567c4d62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80ba9e67def7aefc57e8e4677c9fe018"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a80ba9e67def7aefc57e8e4677c9fe018">__decay_epsilon</a> (self)</td></tr>
<tr class="separator:a80ba9e67def7aefc57e8e4677c9fe018"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad05342bc99909463fa5751f0c40099ac"><td class="memItemLeft" align="right" valign="top">Tuple[ pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor, pytorch.Tensor,]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#ad05342bc99909463fa5751f0c40099ac">__load_random_experiences</a> (self)</td></tr>
<tr class="separator:ad05342bc99909463fa5751f0c40099ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a910e3dd4538aad842778ba8bc96a6df3"><td class="memItemLeft" align="right" valign="top">Dict[str, Any]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a910e3dd4538aad842778ba8bc96a6df3">__process_prioritization_params</a> (self, Dict[str, Any] prioritization_params)</td></tr>
<tr class="separator:a910e3dd4538aad842778ba8bc96a6df3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d116c8aaa8c699eda13ea4641b91270"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#a8d116c8aaa8c699eda13ea4641b91270">__train_policy_model</a> (self)</td></tr>
<tr class="separator:a8d116c8aaa8c699eda13ea4641b91270"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa15b95f5a5d0a93d01594c8657aa3186"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#aa15b95f5a5d0a93d01594c8657aa3186">__update_target_model</a> (self)</td></tr>
<tr class="separator:aa15b95f5a5d0a93d01594c8657aa3186"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-static-methods" name="pri-static-methods"></a>
Static Private Member Functions</h2></td></tr>
<tr class="memitem:ab099cfa7046fe0b29a1bc0f6c0b26eed"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#ab099cfa7046fe0b29a1bc0f6c0b26eed">__anneal_alpha_default_fn</a> (float alpha, float alpha_annealing_factor)</td></tr>
<tr class="separator:ab099cfa7046fe0b29a1bc0f6c0b26eed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc2265abd478e952619075e22a783417"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html#adc2265abd478e952619075e22a783417">__anneal_beta_default_fn</a> (float beta, float beta_annealing_factor)</td></tr>
<tr class="separator:adc2265abd478e952619075e22a783417"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">The DqnAgent class which implements the DQN algorithm on arguments. This class inherits from `Agent`
    class, which is the generic base class for all the agents in the project.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a2b9fa686b41a52da69afea373ee2272d" name="a2b9fa686b41a52da69afea373ee2272d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b9fa686b41a52da69afea373ee2272d">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def rlpack.dqn.dqn_agent.DqnAgent.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.nn.Module&#160;</td>
          <td class="paramname"><em>target_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.nn.Module&#160;</td>
          <td class="paramname"><em>policy_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.optim.Optimizer&#160;</td>
          <td class="paramname"><em>optimizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[LRScheduler, None]&#160;</td>
          <td class="paramname"><em>lr_scheduler</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LossFunction&#160;</td>
          <td class="paramname"><em>loss_function</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>min_epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon_decay_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epsilon_decay_frequency</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>memory_buffer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>target_model_update_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>policy_model_update_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>model_backup_frequency</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>lr_threshold</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_actions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>save_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>device</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Dict[str, Any]] &#160;</td>
          <td class="paramname"><em>prioritization_params</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>force_terminal_state_selection_prob</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>tau</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>apply_norm</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>apply_norm_to</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>eps_for_norm</em> = <code>5e-12</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>p_for_norm</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>dim_for_norm</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">:param target_model: nn.Module: The target network for DQN model. This the network which has
    its weights frozen.
:param policy_model: nn.Module: The policy network for DQN model. This is the network which is trained.
:param optimizer: optim.Optimizer: The optimizer wrapped with policy model's parameters.
:param lr_scheduler: Union[LRScheduler, None]: The PyTorch LR Scheduler with wrapped optimizer.
:param loss_function: LossFunction: The loss function from PyTorch's nn module. Initialized
    instance must be passed.
:param gamma: float: The gamma value for agent.
:param epsilon: float: The initial epsilon for the agent.
:param min_epsilon: float: The minimum epsilon for the agent. Once this value is reached,
    it is maintained for all further episodes.
:param epsilon_decay_rate: float: The decay multiplier to decay the epsilon.
:param epsilon_decay_frequency: int: The number of timesteps after which the epsilon is decayed.
:param memory_buffer_size: int: The buffer size of memory; or replay buffer for DQN.
:param target_model_update_rate: int: The timesteps after which target model's weights are updated with
    policy model weights: weights are weighted as per `tau`: see below)).
:param policy_model_update_rate: int: The timesteps after which policy model is trained. This involves
    backpropagation through the policy network.
:param model_backup_frequency: int: The timesteps after which models are backed up. This will also
    save optimizer, lr_scheduler and agent_states: epsilon the time of saving and memory.
:param lr_threshold: float: The threshold LR which once reached LR scheduler is not called further.
:param batch_size: int: The batch size used for inference through target_model and train through policy model
:param num_actions: int: Number of actions for the environment.
:param save_path: str: The save path for models: target_model and policy_model, optimizer,
    lr_scheduler and agent_states.
:param device: str: The device on which models are run. Default: "cpu".
:param prioritization_params: Optional[Dict[str, Any]]: The parameters for prioritization in prioritized
    memory: or relay buffer). Default: None.
:param force_terminal_state_selection_prob: float: The probability for forcefully selecting a terminal state
    in a batch. Default: 0.0.
:param tau: float: The weighted update of weights from policy_model to target_model. This is done by formula
    target_weight = tau * policy_weight +: 1 - tau) * target_weight/. Default: -1.
:param apply_norm: int: The code to select the normalization procedure to be applied on selected quantities;
    selected by `apply_norm_to`: see below)). Default: -1.
:param apply_norm_to: int: The code to select the quantity to which normalization is to be applied.
    Default: -1.
:param eps_for_norm: float: Epsilon value for normalization: for numeric stability. For min-max normalization
    and standardized normalization. Default: 5e-12.
:param p_for_norm: int: The p value for p-normalization. Default: 2: L2 Norm.
:param dim_for_norm: int: The dimension across which normalization is to be performed. Default: 0.

NOTE:
For prioritization_params, when None: the default) is passed, prioritized memory is not used. To use
    prioritized memory, pass a dictionary with keys `alpha` and `beta`. You can also pass `alpha_decay_rate`
    and `beta_decay_rate` additionally.
The codes for `apply_norm` are given as follows: -
    - No Normalization: -1
    - Min-Max Normalization: 0
    - Standardization: 1
    - P-Normalization: 2
The codes for `apply_norm_to` are given as follows:
    No Normalization: -1
    On States only: 0
    On Rewards only: 1
    On TD value only: 2
    On States and Rewards: 3
    On States and TD: 4
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a364aa41c59de32a363b2e4c241dfef3f">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ab099cfa7046fe0b29a1bc0f6c0b26eed" name="ab099cfa7046fe0b29a1bc0f6c0b26eed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab099cfa7046fe0b29a1bc0f6c0b26eed">&#9670;&#160;</a></span>__anneal_alpha_default_fn()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> float rlpack.dqn.dqn_agent.DqnAgent.__anneal_alpha_default_fn </td>
          <td>(</td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha_annealing_factor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Protected method to anneal alpha parameter for important sampling weights. This will be called
    every `alpha_annealing_frequency` times. `alpha_annealing_frequency` is a key to be passed in dictionary
    `prioritization_params` argument in the DqnAgent class' constructor. This method is called by default
    to anneal alpha.

If `alpha_annealing_frequency` is not passed in `prioritization_params`, the annealing of alpha will not take
    place. This method uses another value `alpha_annealing_factor` that must also be passed in
    `prioritization_params`. `alpha_annealing_factor` is typically below 1 to slowly annealed it to
    0 or `min_alpha`.
</pre> 
</div>
</div>
<a id="adc2265abd478e952619075e22a783417" name="adc2265abd478e952619075e22a783417"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc2265abd478e952619075e22a783417">&#9670;&#160;</a></span>__anneal_beta_default_fn()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> float rlpack.dqn.dqn_agent.DqnAgent.__anneal_beta_default_fn </td>
          <td>(</td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta_annealing_factor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Protected method to anneal beta parameter for important sampling weights. This will be called
    every `beta_annealing_frequency` times. `beta_annealing_frequency` is a key to be passed in dictionary
    `prioritization_params` argument in the DqnAgent class' constructor.

If `beta_annealing_frequency` is not passed in `prioritization_params`, the annealing of beta will not take
    place. This method uses another value `beta_annealing_factor` that must also be passed in
    `prioritization_params`. `beta_annealing_factor` is typically above 1 to slowly annealed it to
    1 or `max_beta`
</pre> 
</div>
</div>
<a id="a80ba9e67def7aefc57e8e4677c9fe018" name="a80ba9e67def7aefc57e8e4677c9fe018"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80ba9e67def7aefc57e8e4677c9fe018">&#9670;&#160;</a></span>__decay_epsilon()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.dqn.dqn_agent.DqnAgent.__decay_epsilon </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Protected method to decay epsilon. This method is called every `epsilon_decay_frequency` timesteps and
    decays the epsilon by `epsilon_decay_rate`, both supplied in DqnAgent class' constructor.
</pre> 
</div>
</div>
<a id="ad05342bc99909463fa5751f0c40099ac" name="ad05342bc99909463fa5751f0c40099ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad05342bc99909463fa5751f0c40099ac">&#9670;&#160;</a></span>__load_random_experiences()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
    ] rlpack.dqn.dqn_agent.DqnAgent.__load_random_experiences </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">This method loads random transitions from memory. This may also include forced terminal states
    if supplied `force_terminal_state_selection_prob` &gt; 0 in DqnAgent constructor for each batch. i.e. if
    force_terminal_state_selection_prob = 0.1, approximately every 1 in 10 batches will have at least
    one terminal state forced by the loader.

:return: Tuple[
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
        pytorch.Tensor,
    ]:
   The tuple of tensors as (states_current, states_next, rewards, actions, dones, priorities,
    probabilities, weights, random_indices).</pre> 
</div>
</div>
<a id="a910e3dd4538aad842778ba8bc96a6df3" name="a910e3dd4538aad842778ba8bc96a6df3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a910e3dd4538aad842778ba8bc96a6df3">&#9670;&#160;</a></span>__process_prioritization_params()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Dict[str, Any] rlpack.dqn.dqn_agent.DqnAgent.__process_prioritization_params </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Dict[str, Any]
    &#160;</td>
          <td class="paramname"><em>prioritization_params</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private method to process the prioritization parameters. This includes sanity check and loading of default
    values of mandatory parameters.
:param prioritization_params: Dict[str, Any]: The prioritization parameters for when
    we use prioritized memory
:return: Dict[str, Any]: The processed prioritization parameters with necessary parameters loaded.
</pre> 
</div>
</div>
<a id="a8d116c8aaa8c699eda13ea4641b91270" name="a8d116c8aaa8c699eda13ea4641b91270"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d116c8aaa8c699eda13ea4641b91270">&#9670;&#160;</a></span>__train_policy_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.dqn.dqn_agent.DqnAgent.__train_policy_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Protected method of the class to train the policy model. This method is called every
    `policy_model_update_rate` timesteps supplied in the DqnAgent class constructor.
This method will load the random samples from memory (number of samples depend on
    `batch_size` supplied in DqnAgent constructor), and train the policy_model.
</pre> 
</div>
</div>
<a id="aa15b95f5a5d0a93d01594c8657aa3186" name="aa15b95f5a5d0a93d01594c8657aa3186"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa15b95f5a5d0a93d01594c8657aa3186">&#9670;&#160;</a></span>__update_target_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.dqn.dqn_agent.DqnAgent.__update_target_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Protected method of the class to update the target model. This method is called every
    `target_model_update_rate` timesteps supplied in the DqnAgent class constructor.
</pre> 
</div>
</div>
<a id="adfd9b38d7e3b4f55eb7f857b0285ae0c" name="adfd9b38d7e3b4f55eb7f857b0285ae0c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adfd9b38d7e3b4f55eb7f857b0285ae0c">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.dqn.dqn_agent.DqnAgent.load </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>custom_name_suffix</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">This method loads the target_model, policy_model, optimizer, lr_scheduler and agent_states from
    the supplied `save_path` argument in the DQN Agent class' constructor (also called __init__).
:param custom_name_suffix: Optional[str]: If supplied, additional suffix is added to names of target_model,
    policy_model, optimizer and lr_scheduler. Useful to load the best model by a custom suffix supplied
    for evaluation. Default: None
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ac493d40ce8bd5562822a01aba0265181">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<a id="a38ee1487797979a2ca7ad4db304d27b4" name="a38ee1487797979a2ca7ad4db304d27b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38ee1487797979a2ca7ad4db304d27b4">&#9670;&#160;</a></span>policy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int rlpack.dqn.dqn_agent.DqnAgent.policy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[ndarray, pytorch.Tensor, List[float]]&#160;</td>
          <td class="paramname"><em>state_current</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The policy for the agent. This runs the inference on policy model with `state_current`
and uses q-values to obtain the best action.
:param state_current: Union[ndarray, pytorch.Tensor, List[float]]: The current state agent is in.
:return: int: The action to be taken.
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ab5e3e4db83e80ef7bb422a148cd3e1f6">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<a id="aabbebafa737394e23228307873976a6b" name="aabbebafa737394e23228307873976a6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabbebafa737394e23228307873976a6b">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.dqn.dqn_agent.DqnAgent.save </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>custom_name_suffix</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">This method saves the target_model, policy_model, optimizer, lr_scheduler and agent_states in the supplied
    `save_path` argument in the DQN Agent class' constructor (also called __init__).
agent_states includes current memory and epsilon values in a dictionary.
:param custom_name_suffix: Optional[str]: If supplied, additional suffix is added to names of target_model,
    policy_model, optimizer and lr_scheduler. Useful to save best model by a custom suffix supplied
    during a train run. Default: None
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#aa61ea2248a43a7bbc9b7c9ab7c240564">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<a id="a61291ffa28e7056e977f8b24259a1008" name="a61291ffa28e7056e977f8b24259a1008"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61291ffa28e7056e977f8b24259a1008">&#9670;&#160;</a></span>temporal_difference()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> pytorch.Tensor rlpack.dqn.dqn_agent.DqnAgent.temporal_difference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>rewards</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>q_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>dones</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">This method computes the temporal difference for given transitions.

:param rewards: pytorch.Tensor: The sampled batch of rewards.
:param q_values: pytorch.Tensor: The q-values inferred from target_model.
:param dones: pytorch.Tensor: The done values for each transition in the batch.
:return: pytorch.Tensor: The TD value for each sample in the batch.
</pre> 
</div>
</div>
<a id="a5f91cd9fcd61a59fd87bd6dde3cf5c8b" name="a5f91cd9fcd61a59fd87bd6dde3cf5c8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f91cd9fcd61a59fd87bd6dde3cf5c8b">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int rlpack.dqn.dqn_agent.DqnAgent.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]&#160;</td>
          <td class="paramname"><em>state_current</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]&#160;</td>
          <td class="paramname"><em>state_next</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[int, float]&#160;</td>
          <td class="paramname"><em>reward</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[int, float]&#160;</td>
          <td class="paramname"><em>action</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[bool, int]&#160;</td>
          <td class="paramname"><em>done</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Union[pytorch.Tensor, np.ndarray, float]] &#160;</td>
          <td class="paramname"><em>priority</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Union[pytorch.Tensor, np.ndarray, float]] &#160;</td>
          <td class="paramname"><em>probability</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Union[pytorch.Tensor, np.ndarray, float]] &#160;</td>
          <td class="paramname"><em>weight</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">- The training method for agent, which accepts a transition from environment and returns an action for next
    transition. Use this method when you intend to train the agent.
- This method will also run the policy to yield the best action for the given state.
- For each transition (or experience) being passed, associated priority, probability and weight
    can be passed.

:param state_current: Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]: The current
    state in the environment.
:param state_next: Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]: The next
    state returned by the environment.
:param reward: Union[int, float]: Reward obtained by performing the action for the transition.
:param action: Union[int, float]: Action taken for the transition
:param done: Union[bool, int]: Indicates weather episode has terminated or not.
:param priority: Optional[Union[pytorch.Tensor, np.ndarray, float]]: The priority of the
    transition: for priority relay memory). Default: 1.0
:param probability: Optional[Union[pytorch.Tensor, np.ndarray, float]]: The probability of the transition
   : for priority relay memory). Default: 1.0
:param weight: Optional[Union[pytorch.Tensor, np.ndarray, float]]: The important sampling weight
    of the transition: for priority relay memory). Default: 1.0
:return: int: The next action to be taken from `state_next`.
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a38c313422ef6c713efd5ef9301b35111">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/kartikrajeshwaran/Library/CloudStorage/GoogleDrive-kartikrajeshwaran.kr@gmail.com/My Drive/Projects/Python/RLPack/rlpack/dqn/dqn_agent.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>rlpack</b></li><li class="navelem"><b>dqn</b></li><li class="navelem"><b>dqn_agent</b></li><li class="navelem"><a class="el" href="classrlpack_1_1dqn_1_1dqn__agent_1_1_dqn_agent.html">DqnAgent</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
