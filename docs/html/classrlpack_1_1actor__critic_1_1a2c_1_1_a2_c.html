<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: rlpack.actor_critic.a2c.A2C Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-static-methods">Static Private Member Functions</a> &#124;
<a href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">rlpack.actor_critic.a2c.A2C Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Inheritance diagram for rlpack.actor_critic.a2c.A2C:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
 <div class="center">
  <img src="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.png" usemap="#rlpack.actor_5Fcritic.a2c.A2C_map" alt=""/>
  <map id="rlpack.actor_5Fcritic.a2c.A2C_map" name="rlpack.actor_5Fcritic.a2c.A2C_map">
<area href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html" alt="rlpack.utils.base.agent.Agent" shape="rect" coords="0,56,176,80"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a09da18ac5db6ca9cb283dec0015b63f6"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#a09da18ac5db6ca9cb283dec0015b63f6">__init__</a> (self, pytorch.nn.Module policy_model, pytorch.optim.Optimizer optimizer, Union[LRScheduler, None] lr_scheduler, LossFunction loss_function, float gamma, float entropy_coefficient, float state_value_coefficient, float lr_threshold, int num_actions, int model_backup_frequency, str save_path, int bootstrap_rounds=1, str device=&quot;cpu&quot;, int apply_norm=-1, int apply_norm_to=-1, float eps_for_norm=5e-12, int p_for_norm=2, int dim_for_norm=0)</td></tr>
<tr class="separator:a09da18ac5db6ca9cb283dec0015b63f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae67c23042778a7f6c3e515939b6b4f4"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#aae67c23042778a7f6c3e515939b6b4f4">compute_advantage</a> (self, pytorch.Tensor returns, pytorch.Tensor state_current_values)</td></tr>
<tr class="separator:aae67c23042778a7f6c3e515939b6b4f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e480b8b9914e283440e5278a97b42cf"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#a5e480b8b9914e283440e5278a97b42cf">policy</a> (self, Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]] state_current, **kwargs)</td></tr>
<tr class="separator:a5e480b8b9914e283440e5278a97b42cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2c4c474849c70cdedf6b98aea2f63c4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#ae2c4c474849c70cdedf6b98aea2f63c4">train</a> (self, Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]] state_current, Union[int, float] reward, Union[bool, int] done, **kwargs)</td></tr>
<tr class="separator:ae2c4c474849c70cdedf6b98aea2f63c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">rlpack.utils.base.agent.Agent</a></td></tr>
<tr class="memitem:accaa47a12b6f65fee88824d3018b8c8e inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Dict[str, Any]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#accaa47a12b6f65fee88824d3018b8c8e">__getstate__</a> (self)</td></tr>
<tr class="separator:accaa47a12b6f65fee88824d3018b8c8e inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a364aa41c59de32a363b2e4c241dfef3f inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a364aa41c59de32a363b2e4c241dfef3f">__init__</a> (self)</td></tr>
<tr class="separator:a364aa41c59de32a363b2e4c241dfef3f inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04286fc7bb9ca0a64bce5eaf3620db7b inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a04286fc7bb9ca0a64bce5eaf3620db7b">__setstate__</a> (self, Dict[str, Any] state)</td></tr>
<tr class="separator:a04286fc7bb9ca0a64bce5eaf3620db7b inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac493d40ce8bd5562822a01aba0265181 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ac493d40ce8bd5562822a01aba0265181">load</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:ac493d40ce8bd5562822a01aba0265181 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5e3e4db83e80ef7bb422a148cd3e1f6 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ab5e3e4db83e80ef7bb422a148cd3e1f6">policy</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:ab5e3e4db83e80ef7bb422a148cd3e1f6 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa61ea2248a43a7bbc9b7c9ab7c240564 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#aa61ea2248a43a7bbc9b7c9ab7c240564">save</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:aa61ea2248a43a7bbc9b7c9ab7c240564 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38c313422ef6c713efd5ef9301b35111 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a38c313422ef6c713efd5ef9301b35111">train</a> (self, *args, **kwargs)</td></tr>
<tr class="separator:a38c313422ef6c713efd5ef9301b35111 inherit pub_methods_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a989698a1260432ca0fcbd1668fe9c7ac"><td class="memItemLeft" align="right" valign="top"><a id="a989698a1260432ca0fcbd1668fe9c7ac" name="a989698a1260432ca0fcbd1668fe9c7ac"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>action_log_probabilities</b></td></tr>
<tr class="separator:a989698a1260432ca0fcbd1668fe9c7ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57416c3545397ddaaa31ee69142e67da"><td class="memItemLeft" align="right" valign="top"><a id="a57416c3545397ddaaa31ee69142e67da" name="a57416c3545397ddaaa31ee69142e67da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>apply_norm</b></td></tr>
<tr class="separator:a57416c3545397ddaaa31ee69142e67da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeef17e7ec0e0b81e2b47b0c4663bad2c"><td class="memItemLeft" align="right" valign="top"><a id="aeef17e7ec0e0b81e2b47b0c4663bad2c" name="aeef17e7ec0e0b81e2b47b0c4663bad2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>apply_norm_to</b></td></tr>
<tr class="separator:aeef17e7ec0e0b81e2b47b0c4663bad2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67a8def97a97cef04686199250556bd0"><td class="memItemLeft" align="right" valign="top"><a id="a67a8def97a97cef04686199250556bd0" name="a67a8def97a97cef04686199250556bd0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>bootstrap_rounds</b></td></tr>
<tr class="separator:a67a8def97a97cef04686199250556bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f3c23d256a14d2b124fb866732051b6"><td class="memItemLeft" align="right" valign="top"><a id="a3f3c23d256a14d2b124fb866732051b6" name="a3f3c23d256a14d2b124fb866732051b6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="separator:a3f3c23d256a14d2b124fb866732051b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3f70110b14a2bc1354fadaa02f3bdff"><td class="memItemLeft" align="right" valign="top"><a id="ac3f70110b14a2bc1354fadaa02f3bdff" name="ac3f70110b14a2bc1354fadaa02f3bdff"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>dim_for_norm</b></td></tr>
<tr class="separator:ac3f70110b14a2bc1354fadaa02f3bdff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac030e4955c3b5317db360d8539e51163"><td class="memItemLeft" align="right" valign="top"><a id="ac030e4955c3b5317db360d8539e51163" name="ac030e4955c3b5317db360d8539e51163"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>entropies</b></td></tr>
<tr class="separator:ac030e4955c3b5317db360d8539e51163"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6def13b25087f4b35685140b0a8e31ff"><td class="memItemLeft" align="right" valign="top"><a id="a6def13b25087f4b35685140b0a8e31ff" name="a6def13b25087f4b35685140b0a8e31ff"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>entropy_coefficient</b></td></tr>
<tr class="separator:a6def13b25087f4b35685140b0a8e31ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad806193a87f792ffdc0e349f0fa5f3e2"><td class="memItemLeft" align="right" valign="top"><a id="ad806193a87f792ffdc0e349f0fa5f3e2" name="ad806193a87f792ffdc0e349f0fa5f3e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>episode_counter</b></td></tr>
<tr class="separator:ad806193a87f792ffdc0e349f0fa5f3e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab79962d551f8a638f440166462456111"><td class="memItemLeft" align="right" valign="top"><a id="ab79962d551f8a638f440166462456111" name="ab79962d551f8a638f440166462456111"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>eps_for_norm</b></td></tr>
<tr class="separator:ab79962d551f8a638f440166462456111"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a335067fc595b3c6bf62395024fd0008a"><td class="memItemLeft" align="right" valign="top"><a id="a335067fc595b3c6bf62395024fd0008a" name="a335067fc595b3c6bf62395024fd0008a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>gamma</b></td></tr>
<tr class="separator:a335067fc595b3c6bf62395024fd0008a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e4dd72ed60c0629e78d9bb7fe22514c"><td class="memItemLeft" align="right" valign="top"><a id="a2e4dd72ed60c0629e78d9bb7fe22514c" name="a2e4dd72ed60c0629e78d9bb7fe22514c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>grad_accumulator</b></td></tr>
<tr class="separator:a2e4dd72ed60c0629e78d9bb7fe22514c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace16f409552ad6b3d8274b91be4b5157"><td class="memItemLeft" align="right" valign="top"><a id="ace16f409552ad6b3d8274b91be4b5157" name="ace16f409552ad6b3d8274b91be4b5157"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss_function</b></td></tr>
<tr class="separator:ace16f409552ad6b3d8274b91be4b5157"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67fd595af5ce5ef1a935083e8383f6af"><td class="memItemLeft" align="right" valign="top"><a id="a67fd595af5ce5ef1a935083e8383f6af" name="a67fd595af5ce5ef1a935083e8383f6af"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>lr_scheduler</b></td></tr>
<tr class="separator:a67fd595af5ce5ef1a935083e8383f6af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a9c00199000d264ab82994aae12b179"><td class="memItemLeft" align="right" valign="top"><a id="a1a9c00199000d264ab82994aae12b179" name="a1a9c00199000d264ab82994aae12b179"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>min_lr</b></td></tr>
<tr class="separator:a1a9c00199000d264ab82994aae12b179"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4da7982764d8eb23165b179a8872d45a"><td class="memItemLeft" align="right" valign="top"><a id="a4da7982764d8eb23165b179a8872d45a" name="a4da7982764d8eb23165b179a8872d45a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>model_backup_frequency</b></td></tr>
<tr class="separator:a4da7982764d8eb23165b179a8872d45a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7f6a7f1f501befd50019ed7f7403bfc"><td class="memItemLeft" align="right" valign="top"><a id="ae7f6a7f1f501befd50019ed7f7403bfc" name="ae7f6a7f1f501befd50019ed7f7403bfc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>normalization</b></td></tr>
<tr class="separator:ae7f6a7f1f501befd50019ed7f7403bfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b420f1579a75aae43c82105a98c311e"><td class="memItemLeft" align="right" valign="top"><a id="a6b420f1579a75aae43c82105a98c311e" name="a6b420f1579a75aae43c82105a98c311e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>num_actions</b></td></tr>
<tr class="separator:a6b420f1579a75aae43c82105a98c311e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a531fa341471a4ad1f97d36c00f221981"><td class="memItemLeft" align="right" valign="top"><a id="a531fa341471a4ad1f97d36c00f221981" name="a531fa341471a4ad1f97d36c00f221981"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>optimizer</b></td></tr>
<tr class="separator:a531fa341471a4ad1f97d36c00f221981"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4f2a8721367dc7865955f308cc6149b"><td class="memItemLeft" align="right" valign="top"><a id="af4f2a8721367dc7865955f308cc6149b" name="af4f2a8721367dc7865955f308cc6149b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>p_for_norm</b></td></tr>
<tr class="separator:af4f2a8721367dc7865955f308cc6149b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a186663b4b9a13fdff2d3a6c068573a4b"><td class="memItemLeft" align="right" valign="top"><a id="a186663b4b9a13fdff2d3a6c068573a4b" name="a186663b4b9a13fdff2d3a6c068573a4b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>policy_model</b></td></tr>
<tr class="separator:a186663b4b9a13fdff2d3a6c068573a4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac30f402e533f0699905a9316f5ff5ab9"><td class="memItemLeft" align="right" valign="top"><a id="ac30f402e533f0699905a9316f5ff5ab9" name="ac30f402e533f0699905a9316f5ff5ab9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>policy_model_parameter_keys</b></td></tr>
<tr class="separator:ac30f402e533f0699905a9316f5ff5ab9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cc2aee9a3fdd63cd263a8600f19eaae"><td class="memItemLeft" align="right" valign="top"><a id="a1cc2aee9a3fdd63cd263a8600f19eaae" name="a1cc2aee9a3fdd63cd263a8600f19eaae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>rewards</b></td></tr>
<tr class="separator:a1cc2aee9a3fdd63cd263a8600f19eaae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affac024bad4b94c555d8299db2e7a64c"><td class="memItemLeft" align="right" valign="top"><a id="affac024bad4b94c555d8299db2e7a64c" name="affac024bad4b94c555d8299db2e7a64c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>save_path</b></td></tr>
<tr class="separator:affac024bad4b94c555d8299db2e7a64c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a808c41752e5a391ccccc5eaa820abc09"><td class="memItemLeft" align="right" valign="top"><a id="a808c41752e5a391ccccc5eaa820abc09" name="a808c41752e5a391ccccc5eaa820abc09"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>state_value_coefficient</b></td></tr>
<tr class="separator:a808c41752e5a391ccccc5eaa820abc09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf2d6eee242ba098e6b977b9b39e5cda"><td class="memItemLeft" align="right" valign="top"><a id="aaf2d6eee242ba098e6b977b9b39e5cda" name="aaf2d6eee242ba098e6b977b9b39e5cda"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>states_current_values</b></td></tr>
<tr class="separator:aaf2d6eee242ba098e6b977b9b39e5cda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa40ba92a0c825186f61c04e9ac713a55"><td class="memItemLeft" align="right" valign="top"><a id="aa40ba92a0c825186f61c04e9ac713a55" name="aa40ba92a0c825186f61c04e9ac713a55"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>step_counter</b></td></tr>
<tr class="separator:aa40ba92a0c825186f61c04e9ac713a55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">rlpack.utils.base.agent.Agent</a></td></tr>
<tr class="memitem:aa4b5b7a651697524896373ca24d0ba16 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="aa4b5b7a651697524896373ca24d0ba16" name="aa4b5b7a651697524896373ca24d0ba16"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>advantage_norm_codes</b></td></tr>
<tr class="separator:aa4b5b7a651697524896373ca24d0ba16 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3ce395269c69c095865fee40818db2e inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="ab3ce395269c69c095865fee40818db2e" name="ab3ce395269c69c095865fee40818db2e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss</b></td></tr>
<tr class="separator:ab3ce395269c69c095865fee40818db2e inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4084a4f3b18536d1c0a871b151971bd7 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="a4084a4f3b18536d1c0a871b151971bd7" name="a4084a4f3b18536d1c0a871b151971bd7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>reward_norm_codes</b></td></tr>
<tr class="separator:a4084a4f3b18536d1c0a871b151971bd7 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4779a7186807d901e8ffc8cc8951527a inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="a4779a7186807d901e8ffc8cc8951527a" name="a4779a7186807d901e8ffc8cc8951527a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>save_path</b></td></tr>
<tr class="separator:a4779a7186807d901e8ffc8cc8951527a inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0500457a682bad272e8e28b9a475fcb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="ae0500457a682bad272e8e28b9a475fcb" name="ae0500457a682bad272e8e28b9a475fcb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>state_norm_codes</b></td></tr>
<tr class="separator:ae0500457a682bad272e8e28b9a475fcb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa672333065b88d4734b58ad8bc1433eb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memItemLeft" align="right" valign="top"><a id="aa672333065b88d4734b58ad8bc1433eb" name="aa672333065b88d4734b58ad8bc1433eb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>td_norm_codes</b></td></tr>
<tr class="separator:aa672333065b88d4734b58ad8bc1433eb inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1agent_1_1_agent"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f">__accumulate_gradients</a> (self)</td></tr>
<tr class="separator:acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe13948ea80cf5b000ec053af95e2c37"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#afe13948ea80cf5b000ec053af95e2c37">__call_train_policy_model</a> (self, Union[bool, int] done)</td></tr>
<tr class="separator:afe13948ea80cf5b000ec053af95e2c37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d0e4e113f005db362a2193915d3523d"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#a7d0e4e113f005db362a2193915d3523d">__clear</a> (self)</td></tr>
<tr class="separator:a7d0e4e113f005db362a2193915d3523d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad37dea33877ba397af1804dee08b894b"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#ad37dea33877ba397af1804dee08b894b">__compute_returns</a> (self)</td></tr>
<tr class="separator:ad37dea33877ba397af1804dee08b894b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af54c8f30f17dabd5d410161107711f0d"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#af54c8f30f17dabd5d410161107711f0d">__train_models</a> (self)</td></tr>
<tr class="separator:af54c8f30f17dabd5d410161107711f0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-static-methods" name="pri-static-methods"></a>
Static Private Member Functions</h2></td></tr>
<tr class="memitem:a197c5334abb53f7852eba483ab4585fd"><td class="memItemLeft" align="right" valign="top">Categorical&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html#a197c5334abb53f7852eba483ab4585fd">__create_action_distribution</a> (pytorch.Tensor actions_logits)</td></tr>
<tr class="separator:a197c5334abb53f7852eba483ab4585fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">The A2C class implements the synchronous Actor-Critic method.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a09da18ac5db6ca9cb283dec0015b63f6" name="a09da18ac5db6ca9cb283dec0015b63f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09da18ac5db6ca9cb283dec0015b63f6">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def rlpack.actor_critic.a2c.A2C.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.nn.Module&#160;</td>
          <td class="paramname"><em>policy_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.optim.Optimizer&#160;</td>
          <td class="paramname"><em>optimizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[LRScheduler, None]&#160;</td>
          <td class="paramname"><em>lr_scheduler</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LossFunction&#160;</td>
          <td class="paramname"><em>loss_function</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>entropy_coefficient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>state_value_coefficient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>lr_threshold</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_actions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>model_backup_frequency</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>save_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>bootstrap_rounds</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>device</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>apply_norm</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>apply_norm_to</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>eps_for_norm</em> = <code>5e-12</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>p_for_norm</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>dim_for_norm</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">:param policy_model: pytorch.nn.Module: The policy model to be used. Policy model must return a tuple of
    action logits and state values.
:param optimizer: pytorch.optim.Optimizer: The optimizer to be used for policy model. Optimizer must be
    initialized and wrapped with policy model parameters.
:param lr_scheduler: Union[LRScheduler, None]: The LR Scheduler to be used to decay the learning rate.
    LR Scheduler must be initialized and wrapped with passed optimizer.
:param loss_function: LossFunction: A PyTorch loss function.
:param gamma: float: The discounting factor for rewards.
:param entropy_coefficient: float: The coefficient to be used for entropy in policy loss computation.
:param state_value_coefficient: float: The coefficient to be used for state value in final loss computation.
:param lr_threshold: float: The threshold LR which once reached LR scheduler is not called further.
:param num_actions: int: Number of actions for the environment.
:param model_backup_frequency: int: The timesteps after which policy model, optimizer states and lr
    scheduler states are backed up.
:param save_path: str: The path where policy model, optimizer states and lr scheduler states are to be saved.
:param bootstrap_rounds: int: The number of rounds until which gradients are to be accumulated before
    performing calling optimizer step. Gradients are mean reduced for bootstrap_rounds &gt; 1. Default: 1.
:param device: str: The device on which models are run. Default: "cpu".
:param apply_norm: int: The code to select the normalization procedure to be applied on selected quantities;
    selected by `apply_norm_to`: see below)). Default: -1.
:param apply_norm_to: int: The code to select the quantity to which normalization is to be applied.
    Default: -1.
:param eps_for_norm: float: Epsilon value for normalization; for numeric stability. For min-max normalization
    and standardized normalization. Default: 5e-12.
:param p_for_norm: int: The p value for p-normalization. Default: 2; L2 Norm.
:param dim_for_norm: int: The dimension across which normalization is to be performed. Default: 0.

The codes for `apply_norm` are given as follows: -
    - No Normalization: -1
    - Min-Max Normalization: 0
    - Standardization: 1
    - P-Normalization: 2
The codes for `apply_norm_to` are given as follows:
    No Normalization: -1
    On States only: 0
    On Rewards only: 1
    On Advantage value only: 2
    On States and Rewards: 3
    On States and Advantage: 4
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a364aa41c59de32a363b2e4c241dfef3f">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f" name="acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd82c3f9cd2ad2d4e0b91d7e3fb5bb5f">&#9670;&#160;</a></span>__accumulate_gradients()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.actor_critic.a2c.A2C.__accumulate_gradients </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private void method to train the model or accumulate the gradients for training.
- If bootstrap_rounds is passed as 1 (default), model is trained each time the method is called.
- If bootstrap_rounds &gt; 1, the gradients are accumulated in grad_accumulator and model is trained via
    __train_models method.
</pre> 
</div>
</div>
<a id="afe13948ea80cf5b000ec053af95e2c37" name="afe13948ea80cf5b000ec053af95e2c37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe13948ea80cf5b000ec053af95e2c37">&#9670;&#160;</a></span>__call_train_policy_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.actor_critic.a2c.A2C.__call_train_policy_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[bool, int]&#160;</td>
          <td class="paramname"><em>done</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private method to call the appropriate method for training policy model based on initialization of A2C agent
:param done: Union[bool, int]: Flag indicating if episode has terminated or not
</pre> 
</div>
</div>
<a id="a7d0e4e113f005db362a2193915d3523d" name="a7d0e4e113f005db362a2193915d3523d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d0e4e113f005db362a2193915d3523d">&#9670;&#160;</a></span>__clear()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.actor_critic.a2c.A2C.__clear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private void method to clear the lists of rewards, action_log_probs and state_values.
</pre> 
</div>
</div>
<a id="ad37dea33877ba397af1804dee08b894b" name="ad37dea33877ba397af1804dee08b894b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad37dea33877ba397af1804dee08b894b">&#9670;&#160;</a></span>__compute_returns()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> pytorch.Tensor rlpack.actor_critic.a2c.A2C.__compute_returns </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Computes the discounted returns iteratively.
:return: pytorch.Tensor: The discounted returns
</pre> 
</div>
</div>
<a id="a197c5334abb53f7852eba483ab4585fd" name="a197c5334abb53f7852eba483ab4585fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a197c5334abb53f7852eba483ab4585fd">&#9670;&#160;</a></span>__create_action_distribution()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Categorical rlpack.actor_critic.a2c.A2C.__create_action_distribution </td>
          <td>(</td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>actions_logits</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private static method to create distributions from action logits
:param actions_logits: pytorch.Tensor: The action logits from policy model
:return: Categorical: A Categorical object initialized with given action logits
</pre> 
</div>
</div>
<a id="af54c8f30f17dabd5d410161107711f0d" name="af54c8f30f17dabd5d410161107711f0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af54c8f30f17dabd5d410161107711f0d">&#9670;&#160;</a></span>__train_models()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.actor_critic.a2c.A2C.__train_models </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Private method to policy model if boostrap_rounds &gt; 1. In such cases the gradients are accumulated in
grad_accumulator. This method collects the accumulated gradients and performs mean reduction and runs
optimizer step.
</pre> 
</div>
</div>
<a id="aae67c23042778a7f6c3e515939b6b4f4" name="aae67c23042778a7f6c3e515939b6b4f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae67c23042778a7f6c3e515939b6b4f4">&#9670;&#160;</a></span>compute_advantage()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> pytorch.Tensor rlpack.actor_critic.a2c.A2C.compute_advantage </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>returns</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>state_current_values</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the advantage from returns and state values
:param returns: pytorch.Tensor: The discounted returns; computed from __compute_returns method
:param state_current_values: pytorch.Tensor: The corresponding state values
:return: pytorch.Tensor: The advantage for the given returns and state values
</pre> 
</div>
</div>
<a id="a5e480b8b9914e283440e5278a97b42cf" name="a5e480b8b9914e283440e5278a97b42cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e480b8b9914e283440e5278a97b42cf">&#9670;&#160;</a></span>policy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int rlpack.actor_critic.a2c.A2C.policy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]&#160;</td>
          <td class="paramname"><em>state_current</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The policy method to evaluate the agent. This runs in pure inference mode.
:param state_current: Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]: The current state returned
    from gym environment
:param kwargs: Other keyword arguments
:return: int: The action to be taken
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#ab5e3e4db83e80ef7bb422a148cd3e1f6">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<a id="ae2c4c474849c70cdedf6b98aea2f63c4" name="ae2c4c474849c70cdedf6b98aea2f63c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2c4c474849c70cdedf6b98aea2f63c4">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int rlpack.actor_critic.a2c.A2C.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]&#160;</td>
          <td class="paramname"><em>state_current</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[int, float]&#160;</td>
          <td class="paramname"><em>reward</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[bool, int]&#160;</td>
          <td class="paramname"><em>done</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The train method to train the agent and underlying policy model.
:param state_current: Union[pytorch.Tensor, np.ndarray, List[Union[float, int]]]: The current state returned
:param reward: Union[int, float]: The reward returned from previous action
:param done: Union[bool, int]: Flag indicating if episode has terminated or not
:param kwargs: Other keyword arguments.
:return: int: The action to be taken
</pre> 
<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html#a38c313422ef6c713efd5ef9301b35111">rlpack.utils.base.agent.Agent</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/kartikrajeshwaran/Library/CloudStorage/GoogleDrive-kartikrajeshwaran.kr@gmail.com/My Drive/Projects/Python/RLPack/rlpack/actor_critic/a2c.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>rlpack</b></li><li class="navelem"><b>actor_critic</b></li><li class="navelem"><b>a2c</b></li><li class="navelem"><a class="el" href="classrlpack_1_1actor__critic_1_1a2c_1_1_a2_c.html">A2C</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
