<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: rlpack.environments.environments.Environments Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrlpack_1_1environments_1_1environments_1_1_environments.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Data Fields</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-static-methods">Static Private Member Functions</a>  </div>
  <div class="headertitle"><div class="title">rlpack.environments.environments.Environments Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>This class is a generic class to train any agent in any environment.  
 <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:abf553aec48455c32925d956b9357775a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#abf553aec48455c32925d956b9357775a">__init__</a> (self, <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">Agent</a> <a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#acf89f40753d4ad36d7b489b7411c4321">agent</a>, Dict[str, Any] <a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a742fc1ce7c0abba5bcc40e897227f230">config</a>, Optional[Callable[[np.ndarray, Tuple[int,...]], np.ndarray]] <a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a70844d4ffd0a91ac5cd8bc36432fc762">reshape_func</a>=None)</td></tr>
<tr class="separator:abf553aec48455c32925d956b9357775a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adba4141e658f1c9e104f3582e964b21c"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#adba4141e658f1c9e104f3582e964b21c">evaluate_agent</a> (self)</td></tr>
<tr class="memdesc:adba4141e658f1c9e104f3582e964b21c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Method to evaluate a trained model.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#adba4141e658f1c9e104f3582e964b21c">More...</a><br /></td></tr>
<tr class="separator:adba4141e658f1c9e104f3582e964b21c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45c51e766cc7da0cde054988358a0798"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a45c51e766cc7da0cde054988358a0798">is_eval</a> (self)</td></tr>
<tr class="memdesc:a45c51e766cc7da0cde054988358a0798"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if environment is to be run in evaluation mode or not.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a45c51e766cc7da0cde054988358a0798">More...</a><br /></td></tr>
<tr class="separator:a45c51e766cc7da0cde054988358a0798"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f3c98aefd7d29d8ffa4de4d19ed9830"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a4f3c98aefd7d29d8ffa4de4d19ed9830">is_train</a> (self)</td></tr>
<tr class="memdesc:a4f3c98aefd7d29d8ffa4de4d19ed9830"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if environment is to be run in training mode or not.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a4f3c98aefd7d29d8ffa4de4d19ed9830">More...</a><br /></td></tr>
<tr class="separator:a4f3c98aefd7d29d8ffa4de4d19ed9830"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05908c3b1269558b074ef0f9f4f6f18a"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a05908c3b1269558b074ef0f9f4f6f18a">train_agent</a> (self, bool render=False, bool load=False, bool plot=False, int verbose=-1, bool distributed_mode=False)</td></tr>
<tr class="memdesc:a05908c3b1269558b074ef0f9f4f6f18a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Method to train the agent in the specified environment.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a05908c3b1269558b074ef0f9f4f6f18a">More...</a><br /></td></tr>
<tr class="separator:a05908c3b1269558b074ef0f9f4f6f18a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Data Fields</h2></td></tr>
<tr class="memitem:acf89f40753d4ad36d7b489b7411c4321"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#acf89f40753d4ad36d7b489b7411c4321">agent</a></td></tr>
<tr class="memdesc:acf89f40753d4ad36d7b489b7411c4321"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input RLPack agent to be run.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#acf89f40753d4ad36d7b489b7411c4321">More...</a><br /></td></tr>
<tr class="separator:acf89f40753d4ad36d7b489b7411c4321"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a742fc1ce7c0abba5bcc40e897227f230"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a742fc1ce7c0abba5bcc40e897227f230">config</a></td></tr>
<tr class="memdesc:a742fc1ce7c0abba5bcc40e897227f230"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input config for setup.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a742fc1ce7c0abba5bcc40e897227f230">More...</a><br /></td></tr>
<tr class="separator:a742fc1ce7c0abba5bcc40e897227f230"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4275964b96a81ab4a7be0782c41b9660"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a4275964b96a81ab4a7be0782c41b9660">env</a></td></tr>
<tr class="memdesc:a4275964b96a81ab4a7be0782c41b9660"><td class="mdescLeft">&#160;</td><td class="mdescRight">The gym environment on which the agent will run.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a4275964b96a81ab4a7be0782c41b9660">More...</a><br /></td></tr>
<tr class="separator:a4275964b96a81ab4a7be0782c41b9660"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48bb4a33dedd6e16dd4276068d6e078b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a48bb4a33dedd6e16dd4276068d6e078b">new_shape</a></td></tr>
<tr class="memdesc:a48bb4a33dedd6e16dd4276068d6e078b"><td class="mdescLeft">&#160;</td><td class="mdescRight">The new shape requested in config to be used with <a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a70844d4ffd0a91ac5cd8bc36432fc762">reshape_func</a>.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a48bb4a33dedd6e16dd4276068d6e078b">More...</a><br /></td></tr>
<tr class="separator:a48bb4a33dedd6e16dd4276068d6e078b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70844d4ffd0a91ac5cd8bc36432fc762"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a70844d4ffd0a91ac5cd8bc36432fc762">reshape_func</a></td></tr>
<tr class="memdesc:a70844d4ffd0a91ac5cd8bc36432fc762"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input reshape function for states.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a70844d4ffd0a91ac5cd8bc36432fc762">More...</a><br /></td></tr>
<tr class="separator:a70844d4ffd0a91ac5cd8bc36432fc762"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:a9e146a1012a89e3f5139b84681a76567"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a9e146a1012a89e3f5139b84681a76567">_generate_plot</a> (self, Dict[int, List[float]] rewards_collector)</td></tr>
<tr class="memdesc:a9e146a1012a89e3f5139b84681a76567"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generates plot with <code>matplotlib</code> for Episodes vs.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a9e146a1012a89e3f5139b84681a76567">More...</a><br /></td></tr>
<tr class="separator:a9e146a1012a89e3f5139b84681a76567"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af71ffa10b18442e31ebe29b6ade58194"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#af71ffa10b18442e31ebe29b6ade58194">_log</a> (self, int ep, float mean_reward, bool distributed_mode, int verbose)</td></tr>
<tr class="memdesc:af71ffa10b18442e31ebe29b6ade58194"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper method to perform logging operations (both on console and cache).  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#af71ffa10b18442e31ebe29b6ade58194">More...</a><br /></td></tr>
<tr class="separator:af71ffa10b18442e31ebe29b6ade58194"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1987b6a7cafb63a58e236f5126661ff0"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a1987b6a7cafb63a58e236f5126661ff0">_remove_log_file</a> (self)</td></tr>
<tr class="memdesc:a1987b6a7cafb63a58e236f5126661ff0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Removes the <code>log.txt</code> file if it is present in the set <code>save_path</code>.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a1987b6a7cafb63a58e236f5126661ff0">More...</a><br /></td></tr>
<tr class="separator:a1987b6a7cafb63a58e236f5126661ff0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91bf94aa46b2b2bdbfb00d531e12f63c"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a91bf94aa46b2b2bdbfb00d531e12f63c">_write_log_file</a> (self, List[str] log)</td></tr>
<tr class="memdesc:a91bf94aa46b2b2bdbfb00d531e12f63c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Writes the logging messages from input to and saves it to set <code>save_path</code> as log.txt.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a91bf94aa46b2b2bdbfb00d531e12f63c">More...</a><br /></td></tr>
<tr class="separator:a91bf94aa46b2b2bdbfb00d531e12f63c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-static-methods" name="pri-static-methods"></a>
Static Private Member Functions</h2></td></tr>
<tr class="memitem:a62caa4981e33980aaad8dc3ced01292d"><td class="memItemLeft" align="right" valign="top">Union[None, float]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a62caa4981e33980aaad8dc3ced01292d">_list_mean</a> (List[Union[float, int]] x)</td></tr>
<tr class="memdesc:a62caa4981e33980aaad8dc3ced01292d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function computes the mean of the input list.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a62caa4981e33980aaad8dc3ced01292d">More...</a><br /></td></tr>
<tr class="separator:a62caa4981e33980aaad8dc3ced01292d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1a1e1918036e0db96b016b8b01726ba"><td class="memItemLeft" align="right" valign="top">np.ndarray&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#ab1a1e1918036e0db96b016b8b01726ba">_reshape_func_default</a> (np.ndarray x, Optional[Tuple[int,...]] shape=None)</td></tr>
<tr class="memdesc:ab1a1e1918036e0db96b016b8b01726ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">This is the default reshape function.  <a href="classrlpack_1_1environments_1_1environments_1_1_environments.html#ab1a1e1918036e0db96b016b8b01726ba">More...</a><br /></td></tr>
<tr class="separator:ab1a1e1918036e0db96b016b8b01726ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >This class is a generic class to train any agent in any environment. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="abf553aec48455c32925d956b9357775a" name="abf553aec48455c32925d956b9357775a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf553aec48455c32925d956b9357775a">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def rlpack.environments.environments.Environments.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">Agent</a>&#160;</td>
          <td class="paramname"><em>agent</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Dict[str, Any]&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[
            Callable[[np.ndarray, Tuple[int, ...]], np.ndarray]
        ] &#160;</td>
          <td class="paramname"><em>reshape_func</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">agent</td><td>Agent: The agent to be trained and/or evaluated in the environment specified in <code>config</code>. </td></tr>
    <tr><td class="paramname">config</td><td>Dict[str, Any]: The configuration setting for experiment. </td></tr>
    <tr><td class="paramname">reshape_func</td><td>Optional[Callable[[np.ndarray, Tuple[int, ...]], np.ndarray]]: The function to reshape the input states. Default: None. Default behavior is to not do any reshaping. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a9e146a1012a89e3f5139b84681a76567" name="a9e146a1012a89e3f5139b84681a76567"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e146a1012a89e3f5139b84681a76567">&#9670;&#160;</a></span>_generate_plot()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments._generate_plot </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Dict[int, List[float]]&#160;</td>
          <td class="paramname"><em>rewards_collector</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Generates plot with <code>matplotlib</code> for Episodes vs. </p>
<p >rewards. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rewards_collector</td><td>Dict[int, List[float]]: Dict of lists of rewards collected in each episode. Each episode is present as a key. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a62caa4981e33980aaad8dc3ced01292d" name="a62caa4981e33980aaad8dc3ced01292d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62caa4981e33980aaad8dc3ced01292d">&#9670;&#160;</a></span>_list_mean()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Union[None, float] rlpack.environments.environments.Environments._list_mean </td>
          <td>(</td>
          <td class="paramtype">List[Union[float, int]]&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function computes the mean of the input list. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>List[Union[float, int]]: The list for which mean is to be computed </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Union[None, float]: The mean value. </dd></dl>

</div>
</div>
<a id="af71ffa10b18442e31ebe29b6ade58194" name="af71ffa10b18442e31ebe29b6ade58194"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af71ffa10b18442e31ebe29b6ade58194">&#9670;&#160;</a></span>_log()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments._log </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ep</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>mean_reward</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>distributed_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int
    &#160;</td>
          <td class="paramname"><em>verbose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Helper method to perform logging operations (both on console and cache). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ep</td><td>int: The episode which is currently being logged. </td></tr>
    <tr><td class="paramname">mean_reward</td><td>float: The mean reward acquired between two successive calls of this method. </td></tr>
    <tr><td class="paramname">distributed_mode</td><td>bool: Indicates if the environment is being run in distributed mode. </td></tr>
    <tr><td class="paramname">verbose</td><td>bool: Indicates the verbose level. Refer notes for more details. This also refers to values logged on screen. If you want to disable the logging on screen, set logging level to WARNING. Default: -1 </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1987b6a7cafb63a58e236f5126661ff0" name="a1987b6a7cafb63a58e236f5126661ff0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1987b6a7cafb63a58e236f5126661ff0">&#9670;&#160;</a></span>_remove_log_file()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments._remove_log_file </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Removes the <code>log.txt</code> file if it is present in the set <code>save_path</code>. </p>

</div>
</div>
<a id="ab1a1e1918036e0db96b016b8b01726ba" name="ab1a1e1918036e0db96b016b8b01726ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1a1e1918036e0db96b016b8b01726ba">&#9670;&#160;</a></span>_reshape_func_default()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> np.ndarray rlpack.environments.environments.Environments._reshape_func_default </td>
          <td>(</td>
          <td class="paramtype">np.ndarray&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Tuple[int, ...]] &#160;</td>
          <td class="paramname"><em>shape</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This is the default reshape function. </p>
<p >If <code>new_shape</code> has been set in config, input states are reshaped to new shapes, else returns the input as it is. Default behavior is not perform any reshaping. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>np.ndarray: The input numpy array to reshape. </td></tr>
    <tr><td class="paramname">shape</td><td>Optional[Tuple[int, ...]]: The new shape to which we want states to be reshaped. Default: None. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>np.ndarray: The reshaped (or unchanged) array. </dd></dl>

</div>
</div>
<a id="a91bf94aa46b2b2bdbfb00d531e12f63c" name="a91bf94aa46b2b2bdbfb00d531e12f63c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91bf94aa46b2b2bdbfb00d531e12f63c">&#9670;&#160;</a></span>_write_log_file()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments._write_log_file </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[str]&#160;</td>
          <td class="paramname"><em>log</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Writes the logging messages from input to and saves it to set <code>save_path</code> as log.txt. </p>
<p >This method open files in append mode. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">log</td><td>List[str]: The logging messages to write </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="adba4141e658f1c9e104f3582e964b21c" name="adba4141e658f1c9e104f3582e964b21c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adba4141e658f1c9e104f3582e964b21c">&#9670;&#160;</a></span>evaluate_agent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments.evaluate_agent </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Method to evaluate a trained model. </p>
<p >This method renders the environment and loads the model from <code>save_path</code>. config must have set mode='eval' to run evaluation. </p>

</div>
</div>
<a id="a45c51e766cc7da0cde054988358a0798" name="a45c51e766cc7da0cde054988358a0798"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45c51e766cc7da0cde054988358a0798">&#9670;&#160;</a></span>is_eval()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool rlpack.environments.environments.Environments.is_eval </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Check if environment is to be run in evaluation mode or not. </p>
<dl class="section return"><dt>Returns</dt><dd>bool: True if evaluation mode is set. </dd></dl>

</div>
</div>
<a id="a4f3c98aefd7d29d8ffa4de4d19ed9830" name="a4f3c98aefd7d29d8ffa4de4d19ed9830"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f3c98aefd7d29d8ffa4de4d19ed9830">&#9670;&#160;</a></span>is_train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool rlpack.environments.environments.Environments.is_train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Check if environment is to be run in training mode or not. </p>
<dl class="section return"><dt>Returns</dt><dd>bool: True if training mode is set. </dd></dl>

</div>
</div>
<a id="a05908c3b1269558b074ef0f9f4f6f18a" name="a05908c3b1269558b074ef0f9f4f6f18a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05908c3b1269558b074ef0f9f4f6f18a">&#9670;&#160;</a></span>train_agent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.environments.environments.Environments.train_agent </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>render</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>load</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>plot</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>distributed_mode</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Method to train the agent in the specified environment. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">render</td><td>bool: Indicates if we wish to render the environment (in animation). Default: False. </td></tr>
    <tr><td class="paramname">load</td><td>bool: Indicates weather to load a previously saved model or train a new one. If set true, config must be <code>save_path</code> or set or environment variable SAVE_PATH must be set. </td></tr>
    <tr><td class="paramname">plot</td><td>bool: Indicates if to plot the training progress. If set True, rewards and episodes are recorded and plot is saved in <code>save_path</code>. </td></tr>
    <tr><td class="paramname">verbose</td><td>bool: Indicates the verbose level. Refer notes for more details. This also refers to values logged on screen. If you want to disable the logging on screen, set logging level to WARNING. Default: -1 </td></tr>
    <tr><td class="paramname">distributed_mode</td><td>Indicates if the environment is being run in distributed mode. Rewards are logged on console every <code>reward_logging_frequency</code> set in the console.</td></tr>
  </table>
  </dd>
</dl>
<p><b>Notes</b></p>
<p >Verbose levels:</p><ul>
<li>-1: Log everything.</li>
<li>0: Log episode wise rewards.</li>
<li>1: Log model level losses.</li>
<li>2: Log Agent specific values. </li>
</ul>

</div>
</div>
<h2 class="groupheader">Field Documentation</h2>
<a id="acf89f40753d4ad36d7b489b7411c4321" name="acf89f40753d4ad36d7b489b7411c4321"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf89f40753d4ad36d7b489b7411c4321">&#9670;&#160;</a></span>agent</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.environments.environments.Environments.agent</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input RLPack agent to be run. </p>

</div>
</div>
<a id="a742fc1ce7c0abba5bcc40e897227f230" name="a742fc1ce7c0abba5bcc40e897227f230"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a742fc1ce7c0abba5bcc40e897227f230">&#9670;&#160;</a></span>config</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.environments.environments.Environments.config</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input config for setup. </p>

</div>
</div>
<a id="a4275964b96a81ab4a7be0782c41b9660" name="a4275964b96a81ab4a7be0782c41b9660"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4275964b96a81ab4a7be0782c41b9660">&#9670;&#160;</a></span>env</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.environments.environments.Environments.env</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The gym environment on which the agent will run. </p>

</div>
</div>
<a id="a48bb4a33dedd6e16dd4276068d6e078b" name="a48bb4a33dedd6e16dd4276068d6e078b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48bb4a33dedd6e16dd4276068d6e078b">&#9670;&#160;</a></span>new_shape</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.environments.environments.Environments.new_shape</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The new shape requested in config to be used with <a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html#a70844d4ffd0a91ac5cd8bc36432fc762">reshape_func</a>. </p>

</div>
</div>
<a id="a70844d4ffd0a91ac5cd8bc36432fc762" name="a70844d4ffd0a91ac5cd8bc36432fc762"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70844d4ffd0a91ac5cd8bc36432fc762">&#9670;&#160;</a></span>reshape_func</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.environments.environments.Environments.reshape_func</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input reshape function for states. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacerlpack.html">rlpack</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1environments.html">environments</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1environments_1_1environments.html">environments</a></li><li class="navelem"><a class="el" href="classrlpack_1_1environments_1_1environments_1_1_environments.html">Environments</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
