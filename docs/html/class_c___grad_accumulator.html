<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: C_GradAccumulator Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('class_c___grad_accumulator.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a>  </div>
  <div class="headertitle"><div class="title">C_GradAccumulator Class Reference<div class="ingroups"><a class="el" href="group__binaries__group.html">binaries</a> &raquo; <a class="el" href="group__grad__accumulator__group.html">grad_accumulator</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>The class <a class="el" href="class_c___grad_accumulator.html" title="The class C_GradAccumulator Accumulates the gradients from model parameters. The binding is done via ...">C_GradAccumulator</a> Accumulates the gradients from model parameters. The binding is done via opaquing the PyTorch Tensors with std::map and hence tensors are moved by references, making the storage efficient. This class is exposed to Python as <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html" title="This class provides the python interface to C_GradAccumulator, the C++ class which performs heavier w...">rlpack._C.grad_accumulator.GradAccumulator</a>.  
 <a href="class_c___grad_accumulator.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_c___grad_accumulator_8h_source.html">C_GradAccumulator.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a696017b1ed9c6a3e5bccccecd9a73e10"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a696017b1ed9c6a3e5bccccecd9a73e10">accumulate</a> (std::map&lt; std::string, torch::Tensor &gt; &amp;namedParameters)</td></tr>
<tr class="separator:a696017b1ed9c6a3e5bccccecd9a73e10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe04783b053cdaa87a490377faac89d8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#abe04783b053cdaa87a490377faac89d8">C_GradAccumulator</a> (std::vector&lt; std::string &gt; &amp;parameterKeys, int64_t boostStrapRounds)</td></tr>
<tr class="separator:abe04783b053cdaa87a490377faac89d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b3b3befbbf516dadbea8676bbcaf52f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a2b3b3befbbf516dadbea8676bbcaf52f">clear</a> ()</td></tr>
<tr class="separator:a2b3b3befbbf516dadbea8676bbcaf52f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacc8717c9c742cfbe88a747c8df51854"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#aacc8717c9c742cfbe88a747c8df51854">delete_item</a> (int64_t index)</td></tr>
<tr class="separator:aacc8717c9c742cfbe88a747c8df51854"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ef3c23ae821e3a53c2d0ec09eb1e939"><td class="memItemLeft" align="right" valign="top">std::map&lt; std::string, torch::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a6ef3c23ae821e3a53c2d0ec09eb1e939">get_item</a> (int64_t index)</td></tr>
<tr class="separator:a6ef3c23ae821e3a53c2d0ec09eb1e939"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5171e9bc7b55f23e179fee896c946a69"><td class="memItemLeft" align="right" valign="top">std::map&lt; std::string, torch::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a5171e9bc7b55f23e179fee896c946a69">mean_reduce</a> ()</td></tr>
<tr class="separator:a5171e9bc7b55f23e179fee896c946a69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7070e708ec92450b0edb3c6ef6b61fff"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a7070e708ec92450b0edb3c6ef6b61fff">set_item</a> (int64_t index, std::map&lt; std::string, torch::Tensor &gt; &amp;namedParameters)</td></tr>
<tr class="separator:a7070e708ec92450b0edb3c6ef6b61fff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a328b0bb90ed7853e7270385c1b2afbea"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a328b0bb90ed7853e7270385c1b2afbea">size</a> ()</td></tr>
<tr class="separator:a328b0bb90ed7853e7270385c1b2afbea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a548330ee790f9eb03ab3f38aa3a33ee7"><td class="memItemLeft" align="right" valign="top">std::map&lt; std::string, torch::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a548330ee790f9eb03ab3f38aa3a33ee7">sum_reduce</a> ()</td></tr>
<tr class="separator:a548330ee790f9eb03ab3f38aa3a33ee7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac99d800fb7cc9eca53cdf7bea982ac04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#ac99d800fb7cc9eca53cdf7bea982ac04">~C_GradAccumulator</a> ()</td></tr>
<tr class="separator:ac99d800fb7cc9eca53cdf7bea982ac04"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a3cb7289bd1dcd654ab0343de19fd8186"><td class="memItemLeft" align="right" valign="top">int64_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a3cb7289bd1dcd654ab0343de19fd8186">bootstrapRounds_</a></td></tr>
<tr class="memdesc:a3cb7289bd1dcd654ab0343de19fd8186"><td class="mdescLeft">&#160;</td><td class="mdescRight">The number of boostrap rounds over which accumulation and reduction is to take place.  <a href="class_c___grad_accumulator.html#a3cb7289bd1dcd654ab0343de19fd8186">More...</a><br /></td></tr>
<tr class="separator:a3cb7289bd1dcd654ab0343de19fd8186"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad59f4483058644f047b7d60381649c23"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::map&lt; std::string, torch::Tensor &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#ad59f4483058644f047b7d60381649c23">namedParametersGrads_</a></td></tr>
<tr class="memdesc:ad59f4483058644f047b7d60381649c23"><td class="mdescLeft">&#160;</td><td class="mdescRight">The vector to accumulate the gradients.  <a href="class_c___grad_accumulator.html#ad59f4483058644f047b7d60381649c23">More...</a><br /></td></tr>
<tr class="separator:ad59f4483058644f047b7d60381649c23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8f64a55b669647e78887385540ebd64"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#ae8f64a55b669647e78887385540ebd64">parameterKeys_</a></td></tr>
<tr class="memdesc:ae8f64a55b669647e78887385540ebd64"><td class="mdescLeft">&#160;</td><td class="mdescRight">The parameter keys for the model for which gradient accumulation is being done.  <a href="class_c___grad_accumulator.html#ae8f64a55b669647e78887385540ebd64">More...</a><br /></td></tr>
<tr class="separator:ae8f64a55b669647e78887385540ebd64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40fc92c6e784f843e631d23844507bd0"><td class="memItemLeft" align="right" valign="top">std::map&lt; std::string, torch::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_c___grad_accumulator.html#a40fc92c6e784f843e631d23844507bd0">reducedParams_</a></td></tr>
<tr class="memdesc:a40fc92c6e784f843e631d23844507bd0"><td class="mdescLeft">&#160;</td><td class="mdescRight">The map to store final results of reduced parameters.  <a href="class_c___grad_accumulator.html#a40fc92c6e784f843e631d23844507bd0">More...</a><br /></td></tr>
<tr class="separator:a40fc92c6e784f843e631d23844507bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >The class <a class="el" href="class_c___grad_accumulator.html" title="The class C_GradAccumulator Accumulates the gradients from model parameters. The binding is done via ...">C_GradAccumulator</a> Accumulates the gradients from model parameters. The binding is done via opaquing the PyTorch Tensors with std::map and hence tensors are moved by references, making the storage efficient. This class is exposed to Python as <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html" title="This class provides the python interface to C_GradAccumulator, the C++ class which performs heavier w...">rlpack._C.grad_accumulator.GradAccumulator</a>. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="abe04783b053cdaa87a490377faac89d8" name="abe04783b053cdaa87a490377faac89d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe04783b053cdaa87a490377faac89d8">&#9670;&#160;</a></span>C_GradAccumulator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">C_GradAccumulator::C_GradAccumulator </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>parameterKeys</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>boostStrapRounds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Class constructor for <a class="el" href="class_c___grad_accumulator.html" title="The class C_GradAccumulator Accumulates the gradients from model parameters. The binding is done via ...">C_GradAccumulator</a>. This class reserves the memory for namedParametersGrads_ for gradient accumulation. This is C++ backend equivalent to <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html#aa9efa4c6f18763846177f16d5b7f52ce">rlpack._C.grad_accumulator.GradAccumulator.__init__</a>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">parameterKeys</td><td>: parameter keys for the model for which gradient accumulation is being done. </td></tr>
    <tr><td class="paramname">boostStrapRounds</td><td>: The number of boostrap rounds over which accumulation and reduction is to take place.</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac99d800fb7cc9eca53cdf7bea982ac04" name="ac99d800fb7cc9eca53cdf7bea982ac04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac99d800fb7cc9eca53cdf7bea982ac04">&#9670;&#160;</a></span>~C_GradAccumulator()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">C_GradAccumulator::~C_GradAccumulator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Default destructor <a class="el" href="class_c___grad_accumulator.html" title="The class C_GradAccumulator Accumulates the gradients from model parameters. The binding is done via ...">C_GradAccumulator</a> </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a696017b1ed9c6a3e5bccccecd9a73e10" name="a696017b1ed9c6a3e5bccccecd9a73e10"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a696017b1ed9c6a3e5bccccecd9a73e10">&#9670;&#160;</a></span>accumulate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void C_GradAccumulator::accumulate </td>
          <td>(</td>
          <td class="paramtype">std::map&lt; std::string, torch::Tensor &gt; &amp;&#160;</td>
          <td class="paramname"><em>namedParameters</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >This method accumulates the gradient from the given named parameters. This method will throw error if you attempt to accumulate more gradients than bootstrapRounds passed in class constructor. This is C++ backend equivalent to <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html#abb7969848a77ce453feaed02d92e7a53" title="Accumulates the parameters from the model.">rlpack._C.grad_accumulator.GradAccumulator.accumulate</a>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">namedParameters</td><td>: Map of named parameters.</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a2b3b3befbbf516dadbea8676bbcaf52f" name="a2b3b3befbbf516dadbea8676bbcaf52f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b3b3befbbf516dadbea8676bbcaf52f">&#9670;&#160;</a></span>clear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void C_GradAccumulator::clear </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Clears all the accumulated gradients. This is C++ backend equivalent to <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html#aeb0009d5af07526a1e5a6e99cbbc6120" title="Clears the accumulated gradients.">rlpack._C.grad_accumulator.GradAccumulator.clear</a>.</p>

</div>
</div>
<a id="aacc8717c9c742cfbe88a747c8df51854" name="aacc8717c9c742cfbe88a747c8df51854"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aacc8717c9c742cfbe88a747c8df51854">&#9670;&#160;</a></span>delete_item()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void C_GradAccumulator::delete_item </td>
          <td>(</td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Method to delete the named parameter gradients in the given index.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>: The index at which we wish to obtain the gradient values.</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6ef3c23ae821e3a53c2d0ec09eb1e939" name="a6ef3c23ae821e3a53c2d0ec09eb1e939"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ef3c23ae821e3a53c2d0ec09eb1e939">&#9670;&#160;</a></span>get_item()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt; std::string, torch::Tensor &gt; C_GradAccumulator::get_item </td>
          <td>(</td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Method to get the named parameter gradients in the given index.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>: The index at which we wish to obtain the gradient values. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: The map of parameter keys and values.</dd></dl>

</div>
</div>
<a id="a5171e9bc7b55f23e179fee896c946a69" name="a5171e9bc7b55f23e179fee896c946a69"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5171e9bc7b55f23e179fee896c946a69">&#9670;&#160;</a></span>mean_reduce()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt; std::string, torch::Tensor &gt; C_GradAccumulator::mean_reduce </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Performs mean reduction of accumulated gradients. This is C++ backend equivalent to <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html#a7eced4b9da86789d45121eff15d10a40" title="Performs the mean reduction of accumulated gradients.">rlpack._C.grad_accumulator.GradAccumulator.mean_reduce</a>.</p>

</div>
</div>
<a id="a7070e708ec92450b0edb3c6ef6b61fff" name="a7070e708ec92450b0edb3c6ef6b61fff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7070e708ec92450b0edb3c6ef6b61fff">&#9670;&#160;</a></span>set_item()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void C_GradAccumulator::set_item </td>
          <td>(</td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::map&lt; std::string, torch::Tensor &gt; &amp;&#160;</td>
          <td class="paramname"><em>namedParameters</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Method to set the named parameter gradients in the given index.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>: The index at which we wish to obtain the gradient values. </td></tr>
    <tr><td class="paramname">namedParameters</td><td>: The item we wish to set at the given index.</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a328b0bb90ed7853e7270385c1b2afbea" name="a328b0bb90ed7853e7270385c1b2afbea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a328b0bb90ed7853e7270385c1b2afbea">&#9670;&#160;</a></span>size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t C_GradAccumulator::size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a548330ee790f9eb03ab3f38aa3a33ee7" name="a548330ee790f9eb03ab3f38aa3a33ee7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a548330ee790f9eb03ab3f38aa3a33ee7">&#9670;&#160;</a></span>sum_reduce()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt; std::string, torch::Tensor &gt; C_GradAccumulator::sum_reduce </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Performs sum reduction of accumulated gradients. This is C++ backend equivalent to <a class="el" href="classrlpack_1_1___c_1_1grad__accumulator_1_1_grad_accumulator.html#a7eced4b9da86789d45121eff15d10a40" title="Performs the mean reduction of accumulated gradients.">rlpack._C.grad_accumulator.GradAccumulator.mean_reduce</a>.</p>

</div>
</div>
<h2 class="groupheader">Field Documentation</h2>
<a id="a3cb7289bd1dcd654ab0343de19fd8186" name="a3cb7289bd1dcd654ab0343de19fd8186"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3cb7289bd1dcd654ab0343de19fd8186">&#9670;&#160;</a></span>bootstrapRounds_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int64_t C_GradAccumulator::bootstrapRounds_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The number of boostrap rounds over which accumulation and reduction is to take place. </p>

</div>
</div>
<a id="ad59f4483058644f047b7d60381649c23" name="ad59f4483058644f047b7d60381649c23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad59f4483058644f047b7d60381649c23">&#9670;&#160;</a></span>namedParametersGrads_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::map&lt;std::string, torch::Tensor&gt; &gt; C_GradAccumulator::namedParametersGrads_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The vector to accumulate the gradients. </p>

</div>
</div>
<a id="ae8f64a55b669647e78887385540ebd64" name="ae8f64a55b669647e78887385540ebd64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8f64a55b669647e78887385540ebd64">&#9670;&#160;</a></span>parameterKeys_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::string&gt; C_GradAccumulator::parameterKeys_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The parameter keys for the model for which gradient accumulation is being done. </p>

</div>
</div>
<a id="a40fc92c6e784f843e631d23844507bd0" name="a40fc92c6e784f843e631d23844507bd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40fc92c6e784f843e631d23844507bd0">&#9670;&#160;</a></span>reducedParams_</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt;std::string, torch::Tensor&gt; C_GradAccumulator::reducedParams_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The map to store final results of reduced parameters. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="class_c___grad_accumulator.html">C_GradAccumulator</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
