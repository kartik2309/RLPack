<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: rlpack.utils.base.trainer_base.TrainerBase Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Data Fields</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-static-methods">Static Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a>  </div>
  <div class="headertitle"><div class="title">rlpack.utils.base.trainer_base.TrainerBase Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>This class is the base class of all trainer classes which implements methods to train an agent.  
 <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#details">More...</a></p>
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Inheritance diagram for rlpack.utils.base.trainer_base.TrainerBase:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<div class="center"><img src="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base__inherit__graph.png" border="0" usemap="#arlpack_8utils_8base_8trainer__base_8_trainer_base_inherit__map" alt="Inheritance graph"/></div>
<map name="arlpack_8utils_8base_8trainer__base_8_trainer_base_inherit__map" id="arlpack_8utils_8base_8trainer__base_8_trainer_base_inherit__map">
<area shape="rect" title="This class is the base class of all trainer classes which implements methods to train an agent." alt="" coords="16,5,173,45"/>
<area shape="rect" href="classrlpack_1_1trainer_1_1trainer_1_1_trainer.html" title="This class is a generic class to train or evaluate any agent in any environment." alt="" coords="5,93,184,119"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base_1_1_generic_func_signature.html">GenericFuncSignature</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Typing hint for a generic function.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base_1_1_generic_func_signature.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a03aa0c4b32bfe5ae66e14df6aa912da6"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a03aa0c4b32bfe5ae66e14df6aa912da6">__init__</a> (self, str <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a376057c6b38bd9d0beef21226a26d570">mode</a>, <a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">Agent</a> <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a5bbedd36b731b61f432aaee2ada19248">agent</a>, gym.Env <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a4e4a1eaf19a960b09af6d831e393c8bd">env</a>, str save_path, Union[SummaryWriter, None] <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a0c06e22415be29579b2f71c2481df926">summary_writer</a>=None, bool <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a089dcf82de62b1dc6b0a25d4e2f69e18">is_distributed</a>=False)</td></tr>
<tr class="memdesc:a03aa0c4b32bfe5ae66e14df6aa912da6"><td class="mdescLeft">&#160;</td><td class="mdescRight">The initializer method (class constructor) for <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html" title="This class is the base class of all trainer classes which implements methods to train an agent.">TrainerBase</a>.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a03aa0c4b32bfe5ae66e14df6aa912da6">More...</a><br /></td></tr>
<tr class="separator:a03aa0c4b32bfe5ae66e14df6aa912da6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f8281c79ba7a9baad6fe57026cd323c"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8f8281c79ba7a9baad6fe57026cd323c">append_reward</a> (self, float reward)</td></tr>
<tr class="memdesc:a8f8281c79ba7a9baad6fe57026cd323c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Append the reward to current list of rewards (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a35a730cd69a9f25ef0557aaa8e624f2b" title="The list of rewards at each timestep.">TrainerBase.rewards</a>).  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8f8281c79ba7a9baad6fe57026cd323c">More...</a><br /></td></tr>
<tr class="separator:a8f8281c79ba7a9baad6fe57026cd323c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e28d5f69a84fe0c17c4cddb8ad6ac2e"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a9e28d5f69a84fe0c17c4cddb8ad6ac2e">clear_cumulative_rewards</a> (self)</td></tr>
<tr class="memdesc:a9e28d5f69a84fe0c17c4cddb8ad6ac2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clears the cumulative rewards accumulated so far.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a9e28d5f69a84fe0c17c4cddb8ad6ac2e">More...</a><br /></td></tr>
<tr class="separator:a9e28d5f69a84fe0c17c4cddb8ad6ac2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90cfba63858a47b1691a5eaba7e330b9"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a90cfba63858a47b1691a5eaba7e330b9">clear_rewards</a> (self)</td></tr>
<tr class="memdesc:a90cfba63858a47b1691a5eaba7e330b9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clear the rewards accumulated so far.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a90cfba63858a47b1691a5eaba7e330b9">More...</a><br /></td></tr>
<tr class="separator:a90cfba63858a47b1691a5eaba7e330b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33d4c8fa96801786dde41b07f3f1e6bd"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a33d4c8fa96801786dde41b07f3f1e6bd">fill_cumulative_reward</a> (self)</td></tr>
<tr class="memdesc:a33d4c8fa96801786dde41b07f3f1e6bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Populates the cumulative rewards (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aa2861dce3797eb0a549686c2822bf2ec" title="The cumulative rewards after each episode.">TrainerBase.cumulative_rewards</a>) list by computing cumulative rewards at the moment.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a33d4c8fa96801786dde41b07f3f1e6bd">More...</a><br /></td></tr>
<tr class="separator:a33d4c8fa96801786dde41b07f3f1e6bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf2ad4e17d6a54f8c243d38b0f80f60f"><td class="memItemLeft" align="right" valign="top">List[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aaf2ad4e17d6a54f8c243d38b0f80f60f">get_loggable_prioritization_quantities</a> (self)</td></tr>
<tr class="memdesc:aaf2ad4e17d6a54f8c243d38b0f80f60f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the list of prioritization quantities that can be logged in current session given the agent by checking if prioritization quantities are present in the agent's "prioritization_params" attribute's key.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aaf2ad4e17d6a54f8c243d38b0f80f60f">More...</a><br /></td></tr>
<tr class="separator:aaf2ad4e17d6a54f8c243d38b0f80f60f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc9267fc369c4038bc716bfbb9f035fb"><td class="memItemLeft" align="right" valign="top">Dict[str, Union[int, float]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#adc9267fc369c4038bc716bfbb9f035fb">get_loggable_prioritization_quantities_by_current_value</a> (self)</td></tr>
<tr class="memdesc:adc9267fc369c4038bc716bfbb9f035fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the current value of loggable prioritization quantities from agent.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#adc9267fc369c4038bc716bfbb9f035fb">More...</a><br /></td></tr>
<tr class="separator:adc9267fc369c4038bc716bfbb9f035fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3341ca3063227402fe82627c483b77a3"><td class="memItemLeft" align="right" valign="top">List[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a3341ca3063227402fe82627c483b77a3">get_loggable_quantities</a> (self)</td></tr>
<tr class="memdesc:a3341ca3063227402fe82627c483b77a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the list of quantities that can be logged in current session given the agent by checking if loggable quantities are present in the agent's attribute.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a3341ca3063227402fe82627c483b77a3">More...</a><br /></td></tr>
<tr class="separator:a3341ca3063227402fe82627c483b77a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaab14bc54e479e59183195c82df860d8"><td class="memItemLeft" align="right" valign="top">Dict[str, Union[int, float, List[float]]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aaab14bc54e479e59183195c82df860d8">get_loggable_quantities_by_current_value</a> (self)</td></tr>
<tr class="memdesc:aaab14bc54e479e59183195c82df860d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the current value of loggable quantities from agent.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aaab14bc54e479e59183195c82df860d8">More...</a><br /></td></tr>
<tr class="separator:aaab14bc54e479e59183195c82df860d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76434f05150ab479cd0eadb7b0cceb7a"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a76434f05150ab479cd0eadb7b0cceb7a">header_line</a> (self)</td></tr>
<tr class="memdesc:a76434f05150ab479cd0eadb7b0cceb7a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Logs header line for block separation.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a76434f05150ab479cd0eadb7b0cceb7a">More...</a><br /></td></tr>
<tr class="separator:a76434f05150ab479cd0eadb7b0cceb7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3041f06fe93603e8b6c8ed7077ce1c7c"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a3041f06fe93603e8b6c8ed7077ce1c7c">is_eval</a> (self)</td></tr>
<tr class="memdesc:a3041f06fe93603e8b6c8ed7077ce1c7c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if environment is to be run in evaluation mode or not.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a3041f06fe93603e8b6c8ed7077ce1c7c">More...</a><br /></td></tr>
<tr class="separator:a3041f06fe93603e8b6c8ed7077ce1c7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af496f618a13b7cc287d8f3c2f4b8db43"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#af496f618a13b7cc287d8f3c2f4b8db43">is_train</a> (self)</td></tr>
<tr class="memdesc:af496f618a13b7cc287d8f3c2f4b8db43"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if environment is to be run in training mode or not.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#af496f618a13b7cc287d8f3c2f4b8db43">More...</a><br /></td></tr>
<tr class="separator:af496f618a13b7cc287d8f3c2f4b8db43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad724c9186152c8a2d4337735331717c0"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#ad724c9186152c8a2d4337735331717c0">log_agent_info_with_py_logger</a> (self, int episode)</td></tr>
<tr class="memdesc:ad724c9186152c8a2d4337735331717c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds agent's loggable quantities to Python logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#ad724c9186152c8a2d4337735331717c0">More...</a><br /></td></tr>
<tr class="separator:ad724c9186152c8a2d4337735331717c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8596a49aaeb959da9cf98ef5a2f9e54d"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8596a49aaeb959da9cf98ef5a2f9e54d">log_agent_info_with_summary_writer</a> (self, int episode)</td></tr>
<tr class="memdesc:a8596a49aaeb959da9cf98ef5a2f9e54d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds agent's loggable quantities to Tensorboard logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8596a49aaeb959da9cf98ef5a2f9e54d">More...</a><br /></td></tr>
<tr class="separator:a8596a49aaeb959da9cf98ef5a2f9e54d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affe535cd605182a720785e1420f756dd"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#affe535cd605182a720785e1420f756dd">log_cumulative_rewards_with_py_logger</a> (self, int episode)</td></tr>
<tr class="memdesc:affe535cd605182a720785e1420f756dd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes average cumulative rewards accumulated so far and logs them with Python logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#affe535cd605182a720785e1420f756dd">More...</a><br /></td></tr>
<tr class="separator:affe535cd605182a720785e1420f756dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c27ff05e21a144e84b37bc618918597"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a9c27ff05e21a144e84b37bc618918597">log_cumulative_rewards_with_summary_writer</a> (self, int episode)</td></tr>
<tr class="memdesc:a9c27ff05e21a144e84b37bc618918597"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes average cumulative rewards accumulated so far and logs them with Tensorboard logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a9c27ff05e21a144e84b37bc618918597">More...</a><br /></td></tr>
<tr class="separator:a9c27ff05e21a144e84b37bc618918597"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a325e8f399892693eee0e1195e41668a5"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a325e8f399892693eee0e1195e41668a5">log_returns_with_py_logger</a> (self, int episode)</td></tr>
<tr class="memdesc:a325e8f399892693eee0e1195e41668a5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes average returns and logs them with Python logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a325e8f399892693eee0e1195e41668a5">More...</a><br /></td></tr>
<tr class="separator:a325e8f399892693eee0e1195e41668a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21d0de415b5446f414a968691c367b6e"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a21d0de415b5446f414a968691c367b6e">log_returns_with_summary_writer</a> (self, int episode)</td></tr>
<tr class="memdesc:a21d0de415b5446f414a968691c367b6e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes average returns and logs them with Tensorboard logger.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a21d0de415b5446f414a968691c367b6e">More...</a><br /></td></tr>
<tr class="separator:a21d0de415b5446f414a968691c367b6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addf41db69b20404858b74cf67de2c48f"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#addf41db69b20404858b74cf67de2c48f">log_reward_with_summary_writer</a> (self, float reward, int episode, int timestep)</td></tr>
<tr class="memdesc:addf41db69b20404858b74cf67de2c48f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes average cumulative rewards accumulated so far and logs them.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#addf41db69b20404858b74cf67de2c48f">More...</a><br /></td></tr>
<tr class="separator:addf41db69b20404858b74cf67de2c48f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ee549a0b1c17dad923bc4e5176e8856"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8ee549a0b1c17dad923bc4e5176e8856">save_agent</a> (self)</td></tr>
<tr class="memdesc:a8ee549a0b1c17dad923bc4e5176e8856"><td class="mdescLeft">&#160;</td><td class="mdescRight">Call to <code>agent.save</code> method.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a8ee549a0b1c17dad923bc4e5176e8856">More...</a><br /></td></tr>
<tr class="separator:a8ee549a0b1c17dad923bc4e5176e8856"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74703b7974ec213fa5b9ce57d09b2ec7"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a74703b7974ec213fa5b9ce57d09b2ec7">save_agent_with_custom_suffix</a> (self, str custom_suffix)</td></tr>
<tr class="memdesc:a74703b7974ec213fa5b9ce57d09b2ec7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Saves the agent with given custom suffix if obtained cumulative reward of the agent is found to be best so far.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a74703b7974ec213fa5b9ce57d09b2ec7">More...</a><br /></td></tr>
<tr class="separator:a74703b7974ec213fa5b9ce57d09b2ec7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Data Fields</h2></td></tr>
<tr class="memitem:a5bbedd36b731b61f432aaee2ada19248"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a5bbedd36b731b61f432aaee2ada19248">agent</a></td></tr>
<tr class="memdesc:a5bbedd36b731b61f432aaee2ada19248"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input RLPack agent to be run.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a5bbedd36b731b61f432aaee2ada19248">More...</a><br /></td></tr>
<tr class="separator:a5bbedd36b731b61f432aaee2ada19248"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2861dce3797eb0a549686c2822bf2ec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aa2861dce3797eb0a549686c2822bf2ec">cumulative_rewards</a></td></tr>
<tr class="memdesc:aa2861dce3797eb0a549686c2822bf2ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">The cumulative rewards after each episode.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aa2861dce3797eb0a549686c2822bf2ec">More...</a><br /></td></tr>
<tr class="separator:aa2861dce3797eb0a549686c2822bf2ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e4a1eaf19a960b09af6d831e393c8bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a4e4a1eaf19a960b09af6d831e393c8bd">env</a></td></tr>
<tr class="memdesc:a4e4a1eaf19a960b09af6d831e393c8bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">The gym environment on which the agent will run.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a4e4a1eaf19a960b09af6d831e393c8bd">More...</a><br /></td></tr>
<tr class="separator:a4e4a1eaf19a960b09af6d831e393c8bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a089dcf82de62b1dc6b0a25d4e2f69e18"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a089dcf82de62b1dc6b0a25d4e2f69e18">is_distributed</a></td></tr>
<tr class="memdesc:a089dcf82de62b1dc6b0a25d4e2f69e18"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>is_distributed</code> indicating if <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html" title="This class is the base class of all trainer classes which implements methods to train an agent.">TrainerBase</a> is launched in multiprocessing setting.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a089dcf82de62b1dc6b0a25d4e2f69e18">More...</a><br /></td></tr>
<tr class="separator:a089dcf82de62b1dc6b0a25d4e2f69e18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a376057c6b38bd9d0beef21226a26d570"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a376057c6b38bd9d0beef21226a26d570">mode</a></td></tr>
<tr class="memdesc:a376057c6b38bd9d0beef21226a26d570"><td class="mdescLeft">&#160;</td><td class="mdescRight">The mode in which trainer will be run (training or evaluation).  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a376057c6b38bd9d0beef21226a26d570">More...</a><br /></td></tr>
<tr class="separator:a376057c6b38bd9d0beef21226a26d570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91d5a6165951e90a574d398f102b9d70"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a91d5a6165951e90a574d398f102b9d70">py_logger</a></td></tr>
<tr class="memdesc:a91d5a6165951e90a574d398f102b9d70"><td class="mdescLeft">&#160;</td><td class="mdescRight">The python logger for logging metrics.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a91d5a6165951e90a574d398f102b9d70">More...</a><br /></td></tr>
<tr class="separator:a91d5a6165951e90a574d398f102b9d70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35a730cd69a9f25ef0557aaa8e624f2b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a35a730cd69a9f25ef0557aaa8e624f2b">rewards</a></td></tr>
<tr class="memdesc:a35a730cd69a9f25ef0557aaa8e624f2b"><td class="mdescLeft">&#160;</td><td class="mdescRight">The list of rewards at each timestep.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a35a730cd69a9f25ef0557aaa8e624f2b">More...</a><br /></td></tr>
<tr class="separator:a35a730cd69a9f25ef0557aaa8e624f2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c06e22415be29579b2f71c2481df926"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a0c06e22415be29579b2f71c2481df926">summary_writer</a></td></tr>
<tr class="memdesc:a0c06e22415be29579b2f71c2481df926"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>summary_writer</code> for tensorboard logging.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a0c06e22415be29579b2f71c2481df926">More...</a><br /></td></tr>
<tr class="separator:a0c06e22415be29579b2f71c2481df926"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:af4b9f77aa32d5064e83a8b698ff0ffe9"><td class="memItemLeft" align="right" valign="top">List[float]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#af4b9f77aa32d5064e83a8b698ff0ffe9">_compute_returns</a> (self)</td></tr>
<tr class="memdesc:af4b9f77aa32d5064e83a8b698ff0ffe9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes returns for accumulated rewards.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#af4b9f77aa32d5064e83a8b698ff0ffe9">More...</a><br /></td></tr>
<tr class="separator:af4b9f77aa32d5064e83a8b698ff0ffe9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a054e3cb4fd20a78fd1c118b2a918a123"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a054e3cb4fd20a78fd1c118b2a918a123">_update_best_reward_value</a> (self)</td></tr>
<tr class="memdesc:a054e3cb4fd20a78fd1c118b2a918a123"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates the current best cumulative reward value (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a30d8eaf8a9f7c0b8c7a3637e0a0f787a" title="The best cumulative reward acquired so far.">TrainerBase._best_cumulative_reward_value</a>) if new cumulative reward is found to be higher than current value.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a054e3cb4fd20a78fd1c118b2a918a123">More...</a><br /></td></tr>
<tr class="separator:a054e3cb4fd20a78fd1c118b2a918a123"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-static-methods" name="pri-static-methods"></a>
Static Private Member Functions</h2></td></tr>
<tr class="memitem:a0f4ba0867b74612be03d4c5590cb941d"><td class="memItemLeft" align="right" valign="top">List[float]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a0f4ba0867b74612be03d4c5590cb941d">_compute_returns_helper</a> (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a35a730cd69a9f25ef0557aaa8e624f2b">rewards</a>, gamma)</td></tr>
<tr class="memdesc:a0f4ba0867b74612be03d4c5590cb941d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper function to compute returns for given rewards.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a0f4ba0867b74612be03d4c5590cb941d">More...</a><br /></td></tr>
<tr class="separator:a0f4ba0867b74612be03d4c5590cb941d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20d90b4a4bd6869ccb9e75c2fe819258"><td class="memItemLeft" align="right" valign="top">logging.Logger&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a20d90b4a4bd6869ccb9e75c2fe819258">_configure_logger</a> (str save_path)</td></tr>
<tr class="separator:a20d90b4a4bd6869ccb9e75c2fe819258"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63e24838d437bf4ccbeb8bd0f34f2dfa"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a63e24838d437bf4ccbeb8bd0f34f2dfa">_execute_func_atomically_</a> (bool <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a089dcf82de62b1dc6b0a25d4e2f69e18">is_distributed</a>, <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base_1_1_generic_func_signature.html">GenericFuncSignature</a> func, int proc=0, *args, **kwargs)</td></tr>
<tr class="memdesc:a63e24838d437bf4ccbeb8bd0f34f2dfa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper function to execute the given function atomically with only one given process.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a63e24838d437bf4ccbeb8bd0f34f2dfa">More...</a><br /></td></tr>
<tr class="separator:a63e24838d437bf4ccbeb8bd0f34f2dfa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a996446d927303cf191310716e8167d49"><td class="memItemLeft" align="right" valign="top">Union[None, float]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a996446d927303cf191310716e8167d49">_list_mean</a> (List[Union[float, int]] x)</td></tr>
<tr class="memdesc:a996446d927303cf191310716e8167d49"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function computes the mean of the input list.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a996446d927303cf191310716e8167d49">More...</a><br /></td></tr>
<tr class="separator:a996446d927303cf191310716e8167d49"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a9c51d43bb667473ddb1fe06c871514"><td class="memItemLeft" align="right" valign="top">np.ndarray&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a7a9c51d43bb667473ddb1fe06c871514">_reshape_func_default</a> (np.ndarray x, Optional[Tuple[int,...]] shape=None)</td></tr>
<tr class="memdesc:a7a9c51d43bb667473ddb1fe06c871514"><td class="mdescLeft">&#160;</td><td class="mdescRight">This is the default reshape function.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a7a9c51d43bb667473ddb1fe06c871514">More...</a><br /></td></tr>
<tr class="separator:a7a9c51d43bb667473ddb1fe06c871514"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a30d8eaf8a9f7c0b8c7a3637e0a0f787a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a30d8eaf8a9f7c0b8c7a3637e0a0f787a">_best_cumulative_reward_value</a></td></tr>
<tr class="memdesc:a30d8eaf8a9f7c0b8c7a3637e0a0f787a"><td class="mdescLeft">&#160;</td><td class="mdescRight">The best cumulative reward acquired so far.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a30d8eaf8a9f7c0b8c7a3637e0a0f787a">More...</a><br /></td></tr>
<tr class="separator:a30d8eaf8a9f7c0b8c7a3637e0a0f787a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec630ba02fffe7b783ea0295beeb5654"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aec630ba02fffe7b783ea0295beeb5654">_log_quantities_agent</a></td></tr>
<tr class="memdesc:aec630ba02fffe7b783ea0295beeb5654"><td class="mdescLeft">&#160;</td><td class="mdescRight">The quantities from agents to log.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aec630ba02fffe7b783ea0295beeb5654">More...</a><br /></td></tr>
<tr class="separator:aec630ba02fffe7b783ea0295beeb5654"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85bcd5a4208c899296246b3340344edf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a85bcd5a4208c899296246b3340344edf">_log_quantities_base</a></td></tr>
<tr class="memdesc:a85bcd5a4208c899296246b3340344edf"><td class="mdescLeft">&#160;</td><td class="mdescRight">The basic quantities to log.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a85bcd5a4208c899296246b3340344edf">More...</a><br /></td></tr>
<tr class="separator:a85bcd5a4208c899296246b3340344edf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52696472fdc68eb3b4185b5e802f117d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a52696472fdc68eb3b4185b5e802f117d">_log_quantities_prioritization</a></td></tr>
<tr class="memdesc:a52696472fdc68eb3b4185b5e802f117d"><td class="mdescLeft">&#160;</td><td class="mdescRight">The prioritization quantities from agents to log.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a52696472fdc68eb3b4185b5e802f117d">More...</a><br /></td></tr>
<tr class="separator:a52696472fdc68eb3b4185b5e802f117d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00e00dc263c4f072f778bf7ff399563d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a00e00dc263c4f072f778bf7ff399563d">_loggable_prioritization_quantities</a></td></tr>
<tr class="memdesc:a00e00dc263c4f072f778bf7ff399563d"><td class="mdescLeft">&#160;</td><td class="mdescRight">The prioritization quantities that can be logged in current session.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a00e00dc263c4f072f778bf7ff399563d">More...</a><br /></td></tr>
<tr class="separator:a00e00dc263c4f072f778bf7ff399563d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac83469c8ac7826d310443544d701ea27"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#ac83469c8ac7826d310443544d701ea27">_loggable_quantities</a></td></tr>
<tr class="memdesc:ac83469c8ac7826d310443544d701ea27"><td class="mdescLeft">&#160;</td><td class="mdescRight">The quantities that can be logged in current session.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#ac83469c8ac7826d310443544d701ea27">More...</a><br /></td></tr>
<tr class="separator:ac83469c8ac7826d310443544d701ea27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08111795fe2c48a2d00a3e5308636ac5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a08111795fe2c48a2d00a3e5308636ac5">_possible_eval_names</a></td></tr>
<tr class="memdesc:a08111795fe2c48a2d00a3e5308636ac5"><td class="mdescLeft">&#160;</td><td class="mdescRight">The possible names for evaluation mode.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a08111795fe2c48a2d00a3e5308636ac5">More...</a><br /></td></tr>
<tr class="separator:a08111795fe2c48a2d00a3e5308636ac5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99bb42fde041c8f76d59d965f455f3ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a99bb42fde041c8f76d59d965f455f3ce">_possible_train_names</a></td></tr>
<tr class="memdesc:a99bb42fde041c8f76d59d965f455f3ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">The possible names for train mode.  <a href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a99bb42fde041c8f76d59d965f455f3ce">More...</a><br /></td></tr>
<tr class="separator:a99bb42fde041c8f76d59d965f455f3ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >This class is the base class of all trainer classes which implements methods to train an agent. </p>
<p >This class implements basic utilities useful for all trainer classes. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a03aa0c4b32bfe5ae66e14df6aa912da6" name="a03aa0c4b32bfe5ae66e14df6aa912da6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03aa0c4b32bfe5ae66e14df6aa912da6">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def rlpack.utils.base.trainer_base.TrainerBase.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrlpack_1_1utils_1_1base_1_1agent_1_1_agent.html">Agent</a>&#160;</td>
          <td class="paramname"><em>agent</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">gym.Env&#160;</td>
          <td class="paramname"><em>env</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>save_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[SummaryWriter, None] &#160;</td>
          <td class="paramname"><em>summary_writer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>is_distributed</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The initializer method (class constructor) for <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html" title="This class is the base class of all trainer classes which implements methods to train an agent.">TrainerBase</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mode</td><td>bool: Current mode of operation of Trainer (training/evaluation). </td></tr>
    <tr><td class="paramname">agent</td><td>Agent: The RLPack Agent to be trained or evaluated. </td></tr>
    <tr><td class="paramname">env</td><td>gym.Env: The gym environment to be used for training or evaluated. </td></tr>
    <tr><td class="paramname">save_path</td><td>str: The path where agent and logs are saved. </td></tr>
    <tr><td class="paramname">summary_writer</td><td>Union[SummaryWriter, None]: An instance of SummaryWriter for tensorboard logging. Default: None </td></tr>
    <tr><td class="paramname">is_distributed</td><td>bool: Flag indicating if current setting is distributed or not. If set to True and is not distributed setting (i.e. dist.init_process_group) has not been called yet, may raise an error. Default: False </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classrlpack_1_1trainer_1_1trainer_1_1_trainer.html#accd9495a26ae02f3157795fde35181ee">rlpack.trainer.trainer.Trainer</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="af4b9f77aa32d5064e83a8b698ff0ffe9" name="af4b9f77aa32d5064e83a8b698ff0ffe9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4b9f77aa32d5064e83a8b698ff0ffe9">&#9670;&#160;</a></span>_compute_returns()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> List[float] rlpack.utils.base.trainer_base.TrainerBase._compute_returns </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes returns for accumulated rewards. </p>
<dl class="section return"><dt>Returns</dt><dd>List[float]: The list of returns at each timestep. </dd></dl>

</div>
</div>
<a id="a0f4ba0867b74612be03d4c5590cb941d" name="a0f4ba0867b74612be03d4c5590cb941d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f4ba0867b74612be03d4c5590cb941d">&#9670;&#160;</a></span>_compute_returns_helper()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> List[float] rlpack.utils.base.trainer_base.TrainerBase._compute_returns_helper </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rewards</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gamma</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Helper function to compute returns for given rewards. </p>
<dl class="section return"><dt>Returns</dt><dd>List[float]: The list of returns at each timestep. </dd></dl>

</div>
</div>
<a id="a20d90b4a4bd6869ccb9e75c2fe819258" name="a20d90b4a4bd6869ccb9e75c2fe819258"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20d90b4a4bd6869ccb9e75c2fe819258">&#9670;&#160;</a></span>_configure_logger()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> logging.Logger rlpack.utils.base.trainer_base.TrainerBase._configure_logger </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>save_path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">save_path</td><td>str: The path to save log file. A file named <code>trainer.log</code> will be created and metrics will be logged into the file. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>logging.Logger: The logger instance for logging </dd></dl>

</div>
</div>
<a id="a63e24838d437bf4ccbeb8bd0f34f2dfa" name="a63e24838d437bf4ccbeb8bd0f34f2dfa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63e24838d437bf4ccbeb8bd0f34f2dfa">&#9670;&#160;</a></span>_execute_func_atomically_()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase._execute_func_atomically_ </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_distributed</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base_1_1_generic_func_signature.html">GenericFuncSignature</a>&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>proc</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Helper function to execute the given function atomically with only one given process. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">is_distributed</td><td>Flag indicating if current setting is distributed or not. If set to True and is not distributed setting (i.e. dist.init_process_group) has not been called yet, will raise an error. </td></tr>
    <tr><td class="paramname">func</td><td><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base_1_1_generic_func_signature.html" title="Typing hint for a generic function.">GenericFuncSignature</a>: The function to be executed. This function must be void and should not return anything. </td></tr>
    <tr><td class="paramname">proc</td><td>int: The process id (local rank) which will execute the <code>func</code>. Default: 0 </td></tr>
    <tr><td class="paramname">args</td><td>Other positional arguments for <code>func</code>. </td></tr>
    <tr><td class="paramname">kwargs</td><td>Other keyword arguments for <code>fund</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a996446d927303cf191310716e8167d49" name="a996446d927303cf191310716e8167d49"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a996446d927303cf191310716e8167d49">&#9670;&#160;</a></span>_list_mean()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Union[None, float] rlpack.utils.base.trainer_base.TrainerBase._list_mean </td>
          <td>(</td>
          <td class="paramtype">List[Union[float, int]]&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function computes the mean of the input list. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>List[Union[float, int]]: The list for which mean is to be computed </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Union[None, float]: The mean value. </dd></dl>

</div>
</div>
<a id="a7a9c51d43bb667473ddb1fe06c871514" name="a7a9c51d43bb667473ddb1fe06c871514"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a9c51d43bb667473ddb1fe06c871514">&#9670;&#160;</a></span>_reshape_func_default()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> np.ndarray rlpack.utils.base.trainer_base.TrainerBase._reshape_func_default </td>
          <td>(</td>
          <td class="paramtype">np.ndarray&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Tuple[int, ...]] &#160;</td>
          <td class="paramname"><em>shape</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This is the default reshape function. </p>
<p >If <code>new_shape</code> has been set in config, input states are reshaped to new shapes, else returns the input as it is. Default behavior is not perform any reshaping. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>np.ndarray: The input numpy array to reshape. </td></tr>
    <tr><td class="paramname">shape</td><td>Optional[Tuple[int, ...]]: The new shape to which we want states to be reshaped. Default: None. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>np.ndarray: The reshaped (or unchanged) array. </dd></dl>

</div>
</div>
<a id="a054e3cb4fd20a78fd1c118b2a918a123" name="a054e3cb4fd20a78fd1c118b2a918a123"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a054e3cb4fd20a78fd1c118b2a918a123">&#9670;&#160;</a></span>_update_best_reward_value()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> bool rlpack.utils.base.trainer_base.TrainerBase._update_best_reward_value </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Updates the current best cumulative reward value (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a30d8eaf8a9f7c0b8c7a3637e0a0f787a" title="The best cumulative reward acquired so far.">TrainerBase._best_cumulative_reward_value</a>) if new cumulative reward is found to be higher than current value. </p>
<dl class="section return"><dt>Returns</dt><dd>bool: Flag indicating if update has occured or not. </dd></dl>

</div>
</div>
<a id="a8f8281c79ba7a9baad6fe57026cd323c" name="a8f8281c79ba7a9baad6fe57026cd323c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f8281c79ba7a9baad6fe57026cd323c">&#9670;&#160;</a></span>append_reward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.append_reward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>reward</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Append the reward to current list of rewards (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#a35a730cd69a9f25ef0557aaa8e624f2b" title="The list of rewards at each timestep.">TrainerBase.rewards</a>). </p>
<p >Ideally this must be called at each timestep. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">reward</td><td>float: The current reward </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9e28d5f69a84fe0c17c4cddb8ad6ac2e" name="a9e28d5f69a84fe0c17c4cddb8ad6ac2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e28d5f69a84fe0c17c4cddb8ad6ac2e">&#9670;&#160;</a></span>clear_cumulative_rewards()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.clear_cumulative_rewards </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clears the cumulative rewards accumulated so far. </p>

</div>
</div>
<a id="a90cfba63858a47b1691a5eaba7e330b9" name="a90cfba63858a47b1691a5eaba7e330b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90cfba63858a47b1691a5eaba7e330b9">&#9670;&#160;</a></span>clear_rewards()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.clear_rewards </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clear the rewards accumulated so far. </p>

</div>
</div>
<a id="a33d4c8fa96801786dde41b07f3f1e6bd" name="a33d4c8fa96801786dde41b07f3f1e6bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33d4c8fa96801786dde41b07f3f1e6bd">&#9670;&#160;</a></span>fill_cumulative_reward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.fill_cumulative_reward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Populates the cumulative rewards (<a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html#aa2861dce3797eb0a549686c2822bf2ec" title="The cumulative rewards after each episode.">TrainerBase.cumulative_rewards</a>) list by computing cumulative rewards at the moment. </p>
<p >This will sum the accumulated rewards and hence ideally must be called after each episode. Post episode, Trainer.clear_rewards method can be called to clear the accumulated rewards </p>

</div>
</div>
<a id="aaf2ad4e17d6a54f8c243d38b0f80f60f" name="aaf2ad4e17d6a54f8c243d38b0f80f60f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf2ad4e17d6a54f8c243d38b0f80f60f">&#9670;&#160;</a></span>get_loggable_prioritization_quantities()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[str] rlpack.utils.base.trainer_base.TrainerBase.get_loggable_prioritization_quantities </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the list of prioritization quantities that can be logged in current session given the agent by checking if prioritization quantities are present in the agent's "prioritization_params" attribute's key. </p>
<dl class="section return"><dt>Returns</dt><dd>List[str]: list of quantities that can be logged in current session given the agent. </dd></dl>

</div>
</div>
<a id="adc9267fc369c4038bc716bfbb9f035fb" name="adc9267fc369c4038bc716bfbb9f035fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc9267fc369c4038bc716bfbb9f035fb">&#9670;&#160;</a></span>get_loggable_prioritization_quantities_by_current_value()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Dict[str, Union[int, float]] rlpack.utils.base.trainer_base.TrainerBase.get_loggable_prioritization_quantities_by_current_value </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtains the current value of loggable prioritization quantities from agent. </p>
<dl class="section return"><dt>Returns</dt><dd>Dict[str, Union[int, float, List[float]]]: The dictionary of current values for each loggable prioritization quantity. </dd></dl>

</div>
</div>
<a id="a3341ca3063227402fe82627c483b77a3" name="a3341ca3063227402fe82627c483b77a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3341ca3063227402fe82627c483b77a3">&#9670;&#160;</a></span>get_loggable_quantities()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[str] rlpack.utils.base.trainer_base.TrainerBase.get_loggable_quantities </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the list of quantities that can be logged in current session given the agent by checking if loggable quantities are present in the agent's attribute. </p>
<dl class="section return"><dt>Returns</dt><dd>List[str]: list of quantities that can be logged in current session given the agent. </dd></dl>

</div>
</div>
<a id="aaab14bc54e479e59183195c82df860d8" name="aaab14bc54e479e59183195c82df860d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaab14bc54e479e59183195c82df860d8">&#9670;&#160;</a></span>get_loggable_quantities_by_current_value()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Dict[str, Union[int, float, List[float]]] rlpack.utils.base.trainer_base.TrainerBase.get_loggable_quantities_by_current_value </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtains the current value of loggable quantities from agent. </p>
<dl class="section return"><dt>Returns</dt><dd>Dict[str, Union[int, float, List[float]]]: The dictionary of current values for each loggable quantity. </dd></dl>

</div>
</div>
<a id="a76434f05150ab479cd0eadb7b0cceb7a" name="a76434f05150ab479cd0eadb7b0cceb7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a76434f05150ab479cd0eadb7b0cceb7a">&#9670;&#160;</a></span>header_line()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.header_line </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Logs header line for block separation. </p>

</div>
</div>
<a id="a3041f06fe93603e8b6c8ed7077ce1c7c" name="a3041f06fe93603e8b6c8ed7077ce1c7c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3041f06fe93603e8b6c8ed7077ce1c7c">&#9670;&#160;</a></span>is_eval()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool rlpack.utils.base.trainer_base.TrainerBase.is_eval </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Check if environment is to be run in evaluation mode or not. </p>
<dl class="section return"><dt>Returns</dt><dd>bool: True if evaluation mode is set. </dd></dl>

</div>
</div>
<a id="af496f618a13b7cc287d8f3c2f4b8db43" name="af496f618a13b7cc287d8f3c2f4b8db43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af496f618a13b7cc287d8f3c2f4b8db43">&#9670;&#160;</a></span>is_train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool rlpack.utils.base.trainer_base.TrainerBase.is_train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Check if environment is to be run in training mode or not. </p>
<dl class="section return"><dt>Returns</dt><dd>bool: True if training mode is set. </dd></dl>

</div>
</div>
<a id="ad724c9186152c8a2d4337735331717c0" name="ad724c9186152c8a2d4337735331717c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad724c9186152c8a2d4337735331717c0">&#9670;&#160;</a></span>log_agent_info_with_py_logger()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_agent_info_with_py_logger </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Adds agent's loggable quantities to Python logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8596a49aaeb959da9cf98ef5a2f9e54d" name="a8596a49aaeb959da9cf98ef5a2f9e54d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8596a49aaeb959da9cf98ef5a2f9e54d">&#9670;&#160;</a></span>log_agent_info_with_summary_writer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_agent_info_with_summary_writer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Adds agent's loggable quantities to Tensorboard logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="affe535cd605182a720785e1420f756dd" name="affe535cd605182a720785e1420f756dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#affe535cd605182a720785e1420f756dd">&#9670;&#160;</a></span>log_cumulative_rewards_with_py_logger()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_cumulative_rewards_with_py_logger </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes average cumulative rewards accumulated so far and logs them with Python logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9c27ff05e21a144e84b37bc618918597" name="a9c27ff05e21a144e84b37bc618918597"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c27ff05e21a144e84b37bc618918597">&#9670;&#160;</a></span>log_cumulative_rewards_with_summary_writer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_cumulative_rewards_with_summary_writer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes average cumulative rewards accumulated so far and logs them with Tensorboard logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a325e8f399892693eee0e1195e41668a5" name="a325e8f399892693eee0e1195e41668a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a325e8f399892693eee0e1195e41668a5">&#9670;&#160;</a></span>log_returns_with_py_logger()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_returns_with_py_logger </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes average returns and logs them with Python logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a21d0de415b5446f414a968691c367b6e" name="a21d0de415b5446f414a968691c367b6e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21d0de415b5446f414a968691c367b6e">&#9670;&#160;</a></span>log_returns_with_summary_writer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_returns_with_summary_writer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes average returns and logs them with Tensorboard logger. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="addf41db69b20404858b74cf67de2c48f" name="addf41db69b20404858b74cf67de2c48f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#addf41db69b20404858b74cf67de2c48f">&#9670;&#160;</a></span>log_reward_with_summary_writer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.log_reward_with_summary_writer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>reward</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>episode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int
    &#160;</td>
          <td class="paramname"><em>timestep</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes average cumulative rewards accumulated so far and logs them. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">reward</td><td>float: The reward obtained at the given timestep. </td></tr>
    <tr><td class="paramname">episode</td><td>int: The current episode for which logging is being done. </td></tr>
    <tr><td class="paramname">timestep</td><td>int: The current timestep of the given episode. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8ee549a0b1c17dad923bc4e5176e8856" name="a8ee549a0b1c17dad923bc4e5176e8856"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ee549a0b1c17dad923bc4e5176e8856">&#9670;&#160;</a></span>save_agent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.save_agent </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Call to <code>agent.save</code> method. </p>
<p >This method executes the save method atomically with only process 0 when there is a multiprocessing or distributed setting. </p>

</div>
</div>
<a id="a74703b7974ec213fa5b9ce57d09b2ec7" name="a74703b7974ec213fa5b9ce57d09b2ec7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74703b7974ec213fa5b9ce57d09b2ec7">&#9670;&#160;</a></span>save_agent_with_custom_suffix()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.utils.base.trainer_base.TrainerBase.save_agent_with_custom_suffix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>custom_suffix</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Saves the agent with given custom suffix if obtained cumulative reward of the agent is found to be best so far. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">custom_suffix</td><td>str: The custom suffix to add to agent's name while saving. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Field Documentation</h2>
<a id="a30d8eaf8a9f7c0b8c7a3637e0a0f787a" name="a30d8eaf8a9f7c0b8c7a3637e0a0f787a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30d8eaf8a9f7c0b8c7a3637e0a0f787a">&#9670;&#160;</a></span>_best_cumulative_reward_value</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._best_cumulative_reward_value</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The best cumulative reward acquired so far. </p>

</div>
</div>
<a id="aec630ba02fffe7b783ea0295beeb5654" name="aec630ba02fffe7b783ea0295beeb5654"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec630ba02fffe7b783ea0295beeb5654">&#9670;&#160;</a></span>_log_quantities_agent</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._log_quantities_agent</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The quantities from agents to log. </p>

</div>
</div>
<a id="a85bcd5a4208c899296246b3340344edf" name="a85bcd5a4208c899296246b3340344edf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85bcd5a4208c899296246b3340344edf">&#9670;&#160;</a></span>_log_quantities_base</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._log_quantities_base</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The basic quantities to log. </p>

</div>
</div>
<a id="a52696472fdc68eb3b4185b5e802f117d" name="a52696472fdc68eb3b4185b5e802f117d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52696472fdc68eb3b4185b5e802f117d">&#9670;&#160;</a></span>_log_quantities_prioritization</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._log_quantities_prioritization</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The prioritization quantities from agents to log. </p>

</div>
</div>
<a id="a00e00dc263c4f072f778bf7ff399563d" name="a00e00dc263c4f072f778bf7ff399563d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00e00dc263c4f072f778bf7ff399563d">&#9670;&#160;</a></span>_loggable_prioritization_quantities</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._loggable_prioritization_quantities</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The prioritization quantities that can be logged in current session. </p>

</div>
</div>
<a id="ac83469c8ac7826d310443544d701ea27" name="ac83469c8ac7826d310443544d701ea27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac83469c8ac7826d310443544d701ea27">&#9670;&#160;</a></span>_loggable_quantities</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._loggable_quantities</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The quantities that can be logged in current session. </p>

</div>
</div>
<a id="a08111795fe2c48a2d00a3e5308636ac5" name="a08111795fe2c48a2d00a3e5308636ac5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08111795fe2c48a2d00a3e5308636ac5">&#9670;&#160;</a></span>_possible_eval_names</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._possible_eval_names</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The possible names for evaluation mode. </p>

</div>
</div>
<a id="a99bb42fde041c8f76d59d965f455f3ce" name="a99bb42fde041c8f76d59d965f455f3ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99bb42fde041c8f76d59d965f455f3ce">&#9670;&#160;</a></span>_possible_train_names</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase._possible_train_names</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The possible names for train mode. </p>

</div>
</div>
<a id="a5bbedd36b731b61f432aaee2ada19248" name="a5bbedd36b731b61f432aaee2ada19248"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bbedd36b731b61f432aaee2ada19248">&#9670;&#160;</a></span>agent</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.agent</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input RLPack agent to be run. </p>

</div>
</div>
<a id="aa2861dce3797eb0a549686c2822bf2ec" name="aa2861dce3797eb0a549686c2822bf2ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2861dce3797eb0a549686c2822bf2ec">&#9670;&#160;</a></span>cumulative_rewards</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.cumulative_rewards</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The cumulative rewards after each episode. </p>

</div>
</div>
<a id="a4e4a1eaf19a960b09af6d831e393c8bd" name="a4e4a1eaf19a960b09af6d831e393c8bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e4a1eaf19a960b09af6d831e393c8bd">&#9670;&#160;</a></span>env</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.env</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The gym environment on which the agent will run. </p>

</div>
</div>
<a id="a089dcf82de62b1dc6b0a25d4e2f69e18" name="a089dcf82de62b1dc6b0a25d4e2f69e18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a089dcf82de62b1dc6b0a25d4e2f69e18">&#9670;&#160;</a></span>is_distributed</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.is_distributed</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>is_distributed</code> indicating if <a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html" title="This class is the base class of all trainer classes which implements methods to train an agent.">TrainerBase</a> is launched in multiprocessing setting. </p>

</div>
</div>
<a id="a376057c6b38bd9d0beef21226a26d570" name="a376057c6b38bd9d0beef21226a26d570"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a376057c6b38bd9d0beef21226a26d570">&#9670;&#160;</a></span>mode</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.mode</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The mode in which trainer will be run (training or evaluation). </p>

</div>
</div>
<a id="a91d5a6165951e90a574d398f102b9d70" name="a91d5a6165951e90a574d398f102b9d70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91d5a6165951e90a574d398f102b9d70">&#9670;&#160;</a></span>py_logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.py_logger</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The python logger for logging metrics. </p>
<p >This is saved in input <code>save_path</code> as trainer.log. </p>

</div>
</div>
<a id="a35a730cd69a9f25ef0557aaa8e624f2b" name="a35a730cd69a9f25ef0557aaa8e624f2b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35a730cd69a9f25ef0557aaa8e624f2b">&#9670;&#160;</a></span>rewards</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.rewards</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The list of rewards at each timestep. </p>

</div>
</div>
<a id="a0c06e22415be29579b2f71c2481df926" name="a0c06e22415be29579b2f71c2481df926"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c06e22415be29579b2f71c2481df926">&#9670;&#160;</a></span>summary_writer</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.utils.base.trainer_base.TrainerBase.summary_writer</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>summary_writer</code> for tensorboard logging. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacerlpack.html">rlpack</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1utils_1_1base.html">base</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1utils_1_1base_1_1trainer__base.html">trainer_base</a></li><li class="navelem"><a class="el" href="classrlpack_1_1utils_1_1base_1_1trainer__base_1_1_trainer_base.html">TrainerBase</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
