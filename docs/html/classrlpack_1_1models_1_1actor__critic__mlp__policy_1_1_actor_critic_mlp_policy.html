<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RLPack: rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="RLPack-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">RLPack
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Data Fields</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-static-methods">Static Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a>  </div>
  <div class="headertitle"><div class="title">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>This class is a PyTorch Model implementing the MLP based Actor-Critic Policy.  
 <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#details">More...</a></p>
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Inheritance diagram for rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<div class="center"><img src="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy__inherit__graph.png" border="0" usemap="#arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_inherit__map" alt="Inheritance graph"/></div>
<map name="arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_inherit__map" id="arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_inherit__map">
<area shape="rect" title="This class is a PyTorch Model implementing the MLP based Actor&#45;Critic Policy." alt="" coords="5,167,196,221"/>
<area shape="rect" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html" title="Base class for all Models in RLPack." alt="" coords="21,79,181,119"/>
<area shape="rect" title=" " alt="" coords="36,5,165,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div id="dynsection-1" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-1-trigger" src="closed.png" alt="+"/> Collaboration diagram for rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy:</div>
<div id="dynsection-1-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-1-content" class="dyncontent" style="display:none;">
<div class="center"><img src="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy__coll__graph.png" border="0" usemap="#arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_coll__map" alt="Collaboration graph"/></div>
<map name="arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_coll__map" id="arlpack_8models_8actor__critic__mlp__policy_8_actor_critic_mlp_policy_coll__map">
<area shape="rect" title="This class is a PyTorch Model implementing the MLP based Actor&#45;Critic Policy." alt="" coords="5,167,196,221"/>
<area shape="rect" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html" title="Base class for all Models in RLPack." alt="" coords="21,79,181,119"/>
<area shape="rect" title=" " alt="" coords="36,5,165,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a3624501903d73e02d5bd1c220b299619"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a3624501903d73e02d5bd1c220b299619">__init__</a> (self, List[int] hidden_sizes, Union[int, Tuple[int, Union[List[int], None]]] action_space, int sequence_length=1, Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]] activation=pytorch.nn.ReLU(), float <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a815a4185be1c351bf7f0e40b26c01749">dropout</a>=0.5, bool <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aecf9f6171326ea4e102b94f500ec83bc">share_network</a>=False, bool <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acc3d0c82767c3101f50c0dd71b9a6e42">use_actor_projection</a>=False, Union[<a class="el" href="classrlpack_1_1exploration_1_1utils_1_1exploration_1_1_exploration.html">Exploration</a>, None] <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a5abaab59fd00400a6fcaaba533fbd201">exploration_tool</a>=None, bool <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a812806819ae4b98740be3dc7f17607f3">use_diagonal_embedding_on_projection</a>=False)</td></tr>
<tr class="memdesc:a3624501903d73e02d5bd1c220b299619"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html" title="This class is a PyTorch Model implementing the MLP based Actor-Critic Policy.">ActorCriticMlpPolicy</a> model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a3624501903d73e02d5bd1c220b299619">More...</a><br /></td></tr>
<tr class="separator:a3624501903d73e02d5bd1c220b299619"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a476460b031bea74417dc8650b17f8c75"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a476460b031bea74417dc8650b17f8c75">clear_noise</a> (self)</td></tr>
<tr class="memdesc:a476460b031bea74417dc8650b17f8c75"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clears the accumulated noise.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a476460b031bea74417dc8650b17f8c75">More...</a><br /></td></tr>
<tr class="separator:a476460b031bea74417dc8650b17f8c75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80306f9557f50f930ca86426af1bd922"><td class="memItemLeft" align="right" valign="top">Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor],]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a80306f9557f50f930ca86426af1bd922">forward</a> (self, pytorch.Tensor x)</td></tr>
<tr class="memdesc:a80306f9557f50f930ca86426af1bd922"><td class="mdescLeft">&#160;</td><td class="mdescRight">The forwards method of the nn.Module.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a80306f9557f50f930ca86426af1bd922">More...</a><br /></td></tr>
<tr class="separator:a80306f9557f50f930ca86426af1bd922"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3ef71ea9ad689862d614e2e2b836380"><td class="memItemLeft" align="right" valign="top">List[pytorch.Tensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#ad3ef71ea9ad689862d614e2e2b836380">get_actor_parameters</a> (self)</td></tr>
<tr class="memdesc:ad3ef71ea9ad689862d614e2e2b836380"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the parameters for actor model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#ad3ef71ea9ad689862d614e2e2b836380">More...</a><br /></td></tr>
<tr class="separator:ad3ef71ea9ad689862d614e2e2b836380"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31a2e5d527024e54a7756530ea9d610c"><td class="memItemLeft" align="right" valign="top">List[pytorch.Tensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a31a2e5d527024e54a7756530ea9d610c">get_critic_parameters</a> (self)</td></tr>
<tr class="memdesc:a31a2e5d527024e54a7756530ea9d610c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the parameters for critic model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a31a2e5d527024e54a7756530ea9d610c">More...</a><br /></td></tr>
<tr class="separator:a31a2e5d527024e54a7756530ea9d610c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87c537f8dca13dac12dd9455e4e460ef"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a87c537f8dca13dac12dd9455e4e460ef">get_noise</a> (self, int at=-1)</td></tr>
<tr class="memdesc:a87c537f8dca13dac12dd9455e4e460ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the noise from <code><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a01b4d6aed4ff2f512c855d7c05978630" title="The noise values for each timestep.">ActorCriticMlpPolicy._noise</a></code> list.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a87c537f8dca13dac12dd9455e4e460ef">More...</a><br /></td></tr>
<tr class="separator:a87c537f8dca13dac12dd9455e4e460ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a071793ef8a858eb9d7858021e337d4bd"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#a071793ef8a858eb9d7858021e337d4bd">__init__</a> (self)</td></tr>
<tr class="memdesc:a071793ef8a858eb9d7858021e337d4bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract init method for <a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html" title="Base class for all Models in RLPack.">Model</a>.  <a href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#a071793ef8a858eb9d7858021e337d4bd">More...</a><br /></td></tr>
<tr class="separator:a071793ef8a858eb9d7858021e337d4bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abeb2e8825db08f887f66a7077f9504f4"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#abeb2e8825db08f887f66a7077f9504f4">forward</a> (self, *args)</td></tr>
<tr class="memdesc:abeb2e8825db08f887f66a7077f9504f4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract forward method for <a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html" title="Base class for all Models in RLPack.">Model</a>.  <a href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#abeb2e8825db08f887f66a7077f9504f4">More...</a><br /></td></tr>
<tr class="separator:abeb2e8825db08f887f66a7077f9504f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Data Fields</h2></td></tr>
<tr class="memitem:aa5cf6dc54f85cb7adb659dcef3cf6302"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aa5cf6dc54f85cb7adb659dcef3cf6302">actor_feature_extractor</a></td></tr>
<tr class="memdesc:aa5cf6dc54f85cb7adb659dcef3cf6302"><td class="mdescLeft">&#160;</td><td class="mdescRight">The feature extractor for actor model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aa5cf6dc54f85cb7adb659dcef3cf6302">More...</a><br /></td></tr>
<tr class="separator:aa5cf6dc54f85cb7adb659dcef3cf6302"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeccac34c455d3068c34a4cde629e7d85"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aeccac34c455d3068c34a4cde629e7d85">actor_head</a></td></tr>
<tr class="memdesc:aeccac34c455d3068c34a4cde629e7d85"><td class="mdescLeft">&#160;</td><td class="mdescRight">The final head for actor; creates logits/parameters for actions.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aeccac34c455d3068c34a4cde629e7d85">More...</a><br /></td></tr>
<tr class="separator:aeccac34c455d3068c34a4cde629e7d85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a077ad80c1325b346324d336ac836cc81"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a077ad80c1325b346324d336ac836cc81">actor_projector</a></td></tr>
<tr class="memdesc:a077ad80c1325b346324d336ac836cc81"><td class="mdescLeft">&#160;</td><td class="mdescRight">The projection vector for actor.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a077ad80c1325b346324d336ac836cc81">More...</a><br /></td></tr>
<tr class="separator:a077ad80c1325b346324d336ac836cc81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa41057f745afd80c3c64913d4a7e9806"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aa41057f745afd80c3c64913d4a7e9806">critic_feature_extractor</a></td></tr>
<tr class="memdesc:aa41057f745afd80c3c64913d4a7e9806"><td class="mdescLeft">&#160;</td><td class="mdescRight">The feature extractor for critic model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aa41057f745afd80c3c64913d4a7e9806">More...</a><br /></td></tr>
<tr class="separator:aa41057f745afd80c3c64913d4a7e9806"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20b1b9443191489e94af5b586d6fae8f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a20b1b9443191489e94af5b586d6fae8f">critic_head</a></td></tr>
<tr class="memdesc:a20b1b9443191489e94af5b586d6fae8f"><td class="mdescLeft">&#160;</td><td class="mdescRight">The final head for critic; creates the state value.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a20b1b9443191489e94af5b586d6fae8f">More...</a><br /></td></tr>
<tr class="separator:a20b1b9443191489e94af5b586d6fae8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a815a4185be1c351bf7f0e40b26c01749"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a815a4185be1c351bf7f0e40b26c01749">dropout</a></td></tr>
<tr class="memdesc:a815a4185be1c351bf7f0e40b26c01749"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input dropout probability.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a815a4185be1c351bf7f0e40b26c01749">More...</a><br /></td></tr>
<tr class="separator:a815a4185be1c351bf7f0e40b26c01749"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5abaab59fd00400a6fcaaba533fbd201"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a5abaab59fd00400a6fcaaba533fbd201">exploration_tool</a></td></tr>
<tr class="memdesc:a5abaab59fd00400a6fcaaba533fbd201"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>exploration_tool</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a5abaab59fd00400a6fcaaba533fbd201">More...</a><br /></td></tr>
<tr class="separator:a5abaab59fd00400a6fcaaba533fbd201"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc989aeb5a2c083821bf19604501f507"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#abc989aeb5a2c083821bf19604501f507">flatten</a></td></tr>
<tr class="memdesc:abc989aeb5a2c083821bf19604501f507"><td class="mdescLeft">&#160;</td><td class="mdescRight">The object to flatten the output fo feature extractor.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#abc989aeb5a2c083821bf19604501f507">More...</a><br /></td></tr>
<tr class="separator:abc989aeb5a2c083821bf19604501f507"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9be4039f8ff54b6045b8e50a0999fbfb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a9be4039f8ff54b6045b8e50a0999fbfb">has_exploration_tool</a></td></tr>
<tr class="memdesc:a9be4039f8ff54b6045b8e50a0999fbfb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flag indicating whether to Model has exploration tool.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a9be4039f8ff54b6045b8e50a0999fbfb">More...</a><br /></td></tr>
<tr class="separator:a9be4039f8ff54b6045b8e50a0999fbfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb05c340b3bf2f6693382040abbda5d3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acb05c340b3bf2f6693382040abbda5d3">mlp_feature_extractor</a></td></tr>
<tr class="memdesc:acb05c340b3bf2f6693382040abbda5d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">The feature extractor instance of rlpack.models._mlp_feature_extractor.MlpFeatureExtractor.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acb05c340b3bf2f6693382040abbda5d3">More...</a><br /></td></tr>
<tr class="separator:acb05c340b3bf2f6693382040abbda5d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aecf9f6171326ea4e102b94f500ec83bc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aecf9f6171326ea4e102b94f500ec83bc">share_network</a></td></tr>
<tr class="memdesc:aecf9f6171326ea4e102b94f500ec83bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>share_network</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aecf9f6171326ea4e102b94f500ec83bc">More...</a><br /></td></tr>
<tr class="separator:aecf9f6171326ea4e102b94f500ec83bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc3d0c82767c3101f50c0dd71b9a6e42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acc3d0c82767c3101f50c0dd71b9a6e42">use_actor_projection</a></td></tr>
<tr class="memdesc:acc3d0c82767c3101f50c0dd71b9a6e42"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>use_actor_projection</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acc3d0c82767c3101f50c0dd71b9a6e42">More...</a><br /></td></tr>
<tr class="separator:acc3d0c82767c3101f50c0dd71b9a6e42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a812806819ae4b98740be3dc7f17607f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a812806819ae4b98740be3dc7f17607f3">use_diagonal_embedding_on_projection</a></td></tr>
<tr class="memdesc:a812806819ae4b98740be3dc7f17607f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">The input <code>use_diagonal_embedding_on_projection</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a812806819ae4b98740be3dc7f17607f3">More...</a><br /></td></tr>
<tr class="separator:a812806819ae4b98740be3dc7f17607f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classrlpack_1_1utils_1_1base_1_1model_1_1_model"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classrlpack_1_1utils_1_1base_1_1model_1_1_model')"><img src="closed.png" alt="-"/>&#160;Data Fields inherited from <a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html">rlpack.utils.base.model.Model</a></td></tr>
<tr class="memitem:a57b1c12763ef030e9826ef980beeef74 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1model_1_1_model"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#a57b1c12763ef030e9826ef980beeef74">has_exploration_tool</a></td></tr>
<tr class="separator:a57b1c12763ef030e9826ef980beeef74 inherit pub_attribs_classrlpack_1_1utils_1_1base_1_1model_1_1_model"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:abd62ffc71bf12fa6a3cc5d90cc222038"><td class="memItemLeft" align="right" valign="top">Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor],]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#abd62ffc71bf12fa6a3cc5d90cc222038">_apply_heads</a> (self, pytorch.Tensor features, Union[pytorch.Tensor, None] state_features=None)</td></tr>
<tr class="memdesc:abd62ffc71bf12fa6a3cc5d90cc222038"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies final heads to input by using actor head and critic head.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#abd62ffc71bf12fa6a3cc5d90cc222038">More...</a><br /></td></tr>
<tr class="separator:abd62ffc71bf12fa6a3cc5d90cc222038"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad28102be7e36eb33c6b784cda834afc"><td class="memItemLeft" align="right" valign="top">Tuple[pytorch.Tensor, pytorch.Tensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aad28102be7e36eb33c6b784cda834afc">_run_non_shared_forward</a> (self, pytorch.Tensor x)</td></tr>
<tr class="memdesc:aad28102be7e36eb33c6b784cda834afc"><td class="mdescLeft">&#160;</td><td class="mdescRight">The forwards method of the nn.Module when actor and critic do not share network.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aad28102be7e36eb33c6b784cda834afc">More...</a><br /></td></tr>
<tr class="separator:aad28102be7e36eb33c6b784cda834afc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b362d5cb00eb166ffb422628f21302e"><td class="memItemLeft" align="right" valign="top">Tuple[Union[List[pytorch.Tensor], pytorch.Tensor], pytorch.Tensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a7b362d5cb00eb166ffb422628f21302e">_run_non_shared_forward_final</a> (self, pytorch.Tensor action_features, pytorch.Tensor state_value_features)</td></tr>
<tr class="memdesc:a7b362d5cb00eb166ffb422628f21302e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Runs the final heads for actor and critic.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a7b362d5cb00eb166ffb422628f21302e">More...</a><br /></td></tr>
<tr class="separator:a7b362d5cb00eb166ffb422628f21302e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad44f288f283b3e0d27fe93efe58128d8"><td class="memItemLeft" align="right" valign="top">pytorch.Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#ad44f288f283b3e0d27fe93efe58128d8">_run_shared_forward</a> (self, pytorch.Tensor x)</td></tr>
<tr class="memdesc:ad44f288f283b3e0d27fe93efe58128d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">The forwards method of the nn.Module when actor and critic share network.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#ad44f288f283b3e0d27fe93efe58128d8">More...</a><br /></td></tr>
<tr class="separator:ad44f288f283b3e0d27fe93efe58128d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b70cfe4902e0950e99ebb05fde565d8"><td class="memItemLeft" align="right" valign="top">Tuple[pytorch.Tensor, pytorch.Tensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a7b70cfe4902e0950e99ebb05fde565d8">_run_shared_forward_final</a> (self, pytorch.Tensor features)</td></tr>
<tr class="memdesc:a7b70cfe4902e0950e99ebb05fde565d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Runs the final heads for actor and critic.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a7b70cfe4902e0950e99ebb05fde565d8">More...</a><br /></td></tr>
<tr class="separator:a7b70cfe4902e0950e99ebb05fde565d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee12333712e55e47dbabf9d6fd463f39"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aee12333712e55e47dbabf9d6fd463f39">_set_non_shared_network_attributes</a> (self, int sequence_length, List[int] hidden_sizes, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>] activation)</td></tr>
<tr class="memdesc:aee12333712e55e47dbabf9d6fd463f39"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets appropriate attributes to create non-shared network.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aee12333712e55e47dbabf9d6fd463f39">More...</a><br /></td></tr>
<tr class="separator:aee12333712e55e47dbabf9d6fd463f39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d9d76361c3730a7038c4b46d91ba222"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a1d9d76361c3730a7038c4b46d91ba222">_set_shared_network_attributes</a> (self, int sequence_length, List[int] hidden_sizes, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>] activation)</td></tr>
<tr class="memdesc:a1d9d76361c3730a7038c4b46d91ba222"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets appropriate attributes to create shared network.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a1d9d76361c3730a7038c4b46d91ba222">More...</a><br /></td></tr>
<tr class="separator:a1d9d76361c3730a7038c4b46d91ba222"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-static-methods" name="pri-static-methods"></a>
Static Private Member Functions</h2></td></tr>
<tr class="memitem:a30304f5d8d09ef4581f2c772f7f9f7d0"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a30304f5d8d09ef4581f2c772f7f9f7d0">_process_action_space</a> (Union[int, List[Union[int, List[int]]]] action_space)</td></tr>
<tr class="memdesc:a30304f5d8d09ef4581f2c772f7f9f7d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Processes <code>action_space</code> for use by the model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a30304f5d8d09ef4581f2c772f7f9f7d0">More...</a><br /></td></tr>
<tr class="separator:a30304f5d8d09ef4581f2c772f7f9f7d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac18c461384c776fbba5d0e0d15cdc6f"><td class="memItemLeft" align="right" valign="top">List[Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aac18c461384c776fbba5d0e0d15cdc6f">_process_activation</a> (Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]] activation, bool <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#acc3d0c82767c3101f50c0dd71b9a6e42">use_actor_projection</a>)</td></tr>
<tr class="memdesc:aac18c461384c776fbba5d0e0d15cdc6f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Processes <code>activation</code> for use by the model.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#aac18c461384c776fbba5d0e0d15cdc6f">More...</a><br /></td></tr>
<tr class="separator:aac18c461384c776fbba5d0e0d15cdc6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a1cad5fd5a8276af751e4f1c2ac0c0e2c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a1cad5fd5a8276af751e4f1c2ac0c0e2c">_action_space_dim</a></td></tr>
<tr class="memdesc:a1cad5fd5a8276af751e4f1c2ac0c0e2c"><td class="mdescLeft">&#160;</td><td class="mdescRight">The output action space dimension as per given <code>action_space</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a1cad5fd5a8276af751e4f1c2ac0c0e2c">More...</a><br /></td></tr>
<tr class="separator:a1cad5fd5a8276af751e4f1c2ac0c0e2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58257bfa075de917a381c1277ed20ab5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a58257bfa075de917a381c1277ed20ab5">_activations</a></td></tr>
<tr class="memdesc:a58257bfa075de917a381c1277ed20ab5"><td class="mdescLeft">&#160;</td><td class="mdescRight">The activations from input <code>activation</code>.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a58257bfa075de917a381c1277ed20ab5">More...</a><br /></td></tr>
<tr class="separator:a58257bfa075de917a381c1277ed20ab5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a740735217565959d556dc9df577e5eee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a740735217565959d556dc9df577e5eee">_apply_actor_activation</a></td></tr>
<tr class="memdesc:a740735217565959d556dc9df577e5eee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flag indicating whether to apply activation to output of actor head or not.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a740735217565959d556dc9df577e5eee">More...</a><br /></td></tr>
<tr class="separator:a740735217565959d556dc9df577e5eee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a424acbf7bc0cd03e9cb230c64cc76bde"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a424acbf7bc0cd03e9cb230c64cc76bde">_apply_critic_activation</a></td></tr>
<tr class="memdesc:a424acbf7bc0cd03e9cb230c64cc76bde"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flag indicating whether to apply activation to output of critic head or not.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a424acbf7bc0cd03e9cb230c64cc76bde">More...</a><br /></td></tr>
<tr class="separator:a424acbf7bc0cd03e9cb230c64cc76bde"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01b4d6aed4ff2f512c855d7c05978630"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a01b4d6aed4ff2f512c855d7c05978630">_noise</a></td></tr>
<tr class="memdesc:a01b4d6aed4ff2f512c855d7c05978630"><td class="mdescLeft">&#160;</td><td class="mdescRight">The noise values for each timestep.  <a href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a01b4d6aed4ff2f512c855d7c05978630">More...</a><br /></td></tr>
<tr class="separator:a01b4d6aed4ff2f512c855d7c05978630"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >This class is a PyTorch Model implementing the MLP based Actor-Critic Policy. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a3624501903d73e02d5bd1c220b299619" name="a3624501903d73e02d5bd1c220b299619"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3624501903d73e02d5bd1c220b299619">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[int]&#160;</td>
          <td class="paramname"><em>hidden_sizes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[int, Tuple[int, Union[List[int], None]]]&#160;</td>
          <td class="paramname"><em>action_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>sequence_length</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]] &#160;</td>
          <td class="paramname"><em>activation</em> = <code>pytorch.nn.ReLU()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>dropout</em> = <code>0.5</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>share_network</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_actor_projection</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[<a class="el" href="classrlpack_1_1exploration_1_1utils_1_1exploration_1_1_exploration.html">Exploration</a>, None] &#160;</td>
          <td class="paramname"><em>exploration_tool</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_diagonal_embedding_on_projection</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialize <a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html" title="This class is a PyTorch Model implementing the MLP based Actor-Critic Policy.">ActorCriticMlpPolicy</a> model. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">hidden_sizes</td><td>List[int]: The list of hidden sizes for each layer. </td></tr>
    <tr><td class="paramname">action_space</td><td>Union[int, Tuple[int, Union[List[int], None]]]: The action space of the environment.<ul>
<li>If discrete action set is used, number of actions can be passed.</li>
<li>If continuous action space is used, a list must be passed with first element representing the output features from model, second element representing the shape of action to be sampled. Second element can be an empty list, if you wish to sample the default no. of samples. </li>
</ul>
</td></tr>
    <tr><td class="paramname">sequence_length</td><td>int: The sequence length of the expected tensor. Default: 1 </td></tr>
    <tr><td class="paramname">activation</td><td>Union[Activation, List[Activation]]: The activation function class(es) for the model. Must be an initialized activation object from PyTorch's nn (torch.nn) module. If a list is passed, List must be of length [1, 3], first activation for feature extractor, second for actor head and third for critic head. </td></tr>
    <tr><td class="paramname">dropout</td><td>float: The dropout to be used in the final Linear (FC) layer. Default: 0.5 </td></tr>
    <tr><td class="paramname">share_network</td><td>bool: Flag indicating whether to use the shared network for actor and critic or separate networks. Default: False </td></tr>
    <tr><td class="paramname">use_actor_projection</td><td>bool: Flag indicating whether to use projection for actor. Projection is applied to output of feature extractor of actor model. Default: False. </td></tr>
    <tr><td class="paramname">exploration_tool</td><td>Union[Exploration, None]: The exploration tool to be used for exploring the environment. The noise can be obtained using <code>get_noise</code> method and exploration tool must have <code>rsample</code> method implemented. </td></tr>
    <tr><td class="paramname">use_diagonal_embedding_on_projection</td><td>bool: The flag indicating whether to perform diagonal embedding on projected action values from actor i.e. create a diagonal covariance matrix. This is only active when <code>use_actor_projection</code> is True. Default: False </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#a071793ef8a858eb9d7858021e337d4bd">rlpack.utils.base.model.Model</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="abd62ffc71bf12fa6a3cc5d90cc222038" name="abd62ffc71bf12fa6a3cc5d90cc222038"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd62ffc71bf12fa6a3cc5d90cc222038">&#9670;&#160;</a></span>_apply_heads()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Union[
        Tuple[List[pytorch.Tensor], pytorch.Tensor],
        Tuple[pytorch.Tensor, pytorch.Tensor],
    ] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._apply_heads </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[pytorch.Tensor, None] &#160;</td>
          <td class="paramname"><em>state_features</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies final heads to input by using actor head and critic head. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">features</td><td>pytorch.Tensor: The pytorch tensor of features. When using non-shared actor-critic, this refers to actor features. When using shared actor-critic, this refers to features from common feature extractor. </td></tr>
    <tr><td class="paramname">state_features</td><td>Union[pytorch.Tensor, None]: The state features if using non-shared actor-critic. If using shared, must be None. Default: None </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor], ]: The tuple of tensors for actor and critic. </dd></dl>

</div>
</div>
<a id="a30304f5d8d09ef4581f2c772f7f9f7d0" name="a30304f5d8d09ef4581f2c772f7f9f7d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30304f5d8d09ef4581f2c772f7f9f7d0">&#9670;&#160;</a></span>_process_action_space()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> int rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._process_action_space </td>
          <td>(</td>
          <td class="paramtype">Union[int, List[Union[int, List[int]]]]&#160;</td>
          <td class="paramname"><em>action_space</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Processes <code>action_space</code> for use by the model. </p>
<p >If checks are passed, returns the output features for actor head. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">action_space</td><td>Union[int, List[Union[int, List[int]]]]: The action space of the environment. If discrete action set is used, number of actions can be passed. If continuous action space is used, a list must be passed with first element representing the output features from model, second representing the shape of action to be sampled.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: Tuple[Union[int, List[Union[int, List[int]]]], Union[Activation, List[Activation]]]: The corrected values for action_space and activation if required. </dd></dl>

</div>
</div>
<a id="aac18c461384c776fbba5d0e0d15cdc6f" name="aac18c461384c776fbba5d0e0d15cdc6f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac18c461384c776fbba5d0e0d15cdc6f">&#9670;&#160;</a></span>_process_activation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> List[Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]]] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._process_activation </td>
          <td>(</td>
          <td class="paramtype">Union[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>, List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]]&#160;</td>
          <td class="paramname"><em>activation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool
    &#160;</td>
          <td class="paramname"><em>use_actor_projection</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Processes <code>activation</code> for use by the model. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">activation</td><td>Union[Activation, List[Activation]]: The activation function class(es) for the model. Must be an initialized activation object from PyTorch's nn (torch.nn) module. If a list is passed, List must be of length [1, 3], first activation for feature extractor, second for actor head and third for critic head. </td></tr>
    <tr><td class="paramname">use_actor_projection</td><td>bool: Flag indicating whether to use projection for actor. Projection is applied to output of feature extractor of actor model. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aad28102be7e36eb33c6b784cda834afc" name="aad28102be7e36eb33c6b784cda834afc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad28102be7e36eb33c6b784cda834afc">&#9670;&#160;</a></span>_run_non_shared_forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[pytorch.Tensor, pytorch.Tensor] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._run_non_shared_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The forwards method of the nn.Module when actor and critic do not share network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>pytorch.Tensor: The model input. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor, pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor, pytorch.Tensor], ]: The tuple of actor and critic outputs. </dd></dl>

</div>
</div>
<a id="a7b362d5cb00eb166ffb422628f21302e" name="a7b362d5cb00eb166ffb422628f21302e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b362d5cb00eb166ffb422628f21302e">&#9670;&#160;</a></span>_run_non_shared_forward_final()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Union[List[pytorch.Tensor], pytorch.Tensor], pytorch.Tensor] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._run_non_shared_forward_final </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>action_features</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>state_value_features</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Runs the final heads for actor and critic. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">action_features</td><td>The pytorch tensor of features from action feature extractor. </td></tr>
    <tr><td class="paramname">state_value_features</td><td>The pytorch tensor of features from critic feature extractor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: Tuple[Union[List[pytorch.Tensor], pytorch.Tensor], pytorch.Tensor]: Tuple of tensors for actor and critic. </dd></dl>

</div>
</div>
<a id="ad44f288f283b3e0d27fe93efe58128d8" name="ad44f288f283b3e0d27fe93efe58128d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad44f288f283b3e0d27fe93efe58128d8">&#9670;&#160;</a></span>_run_shared_forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> pytorch.Tensor rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._run_shared_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor&#160;</td>
          <td class="paramname"><em>x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The forwards method of the nn.Module when actor and critic share network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>pytorch.Tensor: The model input. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor, pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor, pytorch.Tensor], ]: The tuple of actor and critic outputs. </dd></dl>

</div>
</div>
<a id="a7b70cfe4902e0950e99ebb05fde565d8" name="a7b70cfe4902e0950e99ebb05fde565d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b70cfe4902e0950e99ebb05fde565d8">&#9670;&#160;</a></span>_run_shared_forward_final()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[pytorch.Tensor, pytorch.Tensor] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._run_shared_forward_final </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>features</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Runs the final heads for actor and critic. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">features</td><td>The pytorch tensor of features from common feature extractor for actor and critic. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: Tuple[pytorch.Tensor, pytorch.Tensor]: Tuple of tensors for actor and critic. </dd></dl>

</div>
</div>
<a id="aee12333712e55e47dbabf9d6fd463f39" name="aee12333712e55e47dbabf9d6fd463f39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee12333712e55e47dbabf9d6fd463f39">&#9670;&#160;</a></span>_set_non_shared_network_attributes()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._set_non_shared_network_attributes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[int]&#160;</td>
          <td class="paramname"><em>hidden_sizes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]&#160;</td>
          <td class="paramname"><em>activation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets appropriate attributes to create non-shared network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sequence_length</td><td>int: The sequence length of the expected tensor. </td></tr>
    <tr><td class="paramname">hidden_sizes</td><td>List[int]: The list of hidden sizes for each layer. </td></tr>
    <tr><td class="paramname">activation</td><td>List[Activation]: List of activations to be used. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1d9d76361c3730a7038c4b46d91ba222" name="a1d9d76361c3730a7038c4b46d91ba222"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d9d76361c3730a7038c4b46d91ba222">&#9670;&#160;</a></span>_set_shared_network_attributes()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._set_shared_network_attributes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[int]&#160;</td>
          <td class="paramname"><em>hidden_sizes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[<a class="el" href="classrlpack_1_1utils_1_1typing__hints_1_1_activation.html">Activation</a>]&#160;</td>
          <td class="paramname"><em>activation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets appropriate attributes to create shared network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sequence_length</td><td>int: The sequence length of the expected tensor. </td></tr>
    <tr><td class="paramname">hidden_sizes</td><td>List[int]: The list of hidden sizes for each layer. </td></tr>
    <tr><td class="paramname">activation</td><td>List[Activation]: List of activations to be used. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a476460b031bea74417dc8650b17f8c75" name="a476460b031bea74417dc8650b17f8c75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a476460b031bea74417dc8650b17f8c75">&#9670;&#160;</a></span>clear_noise()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.clear_noise </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clears the accumulated noise. </p>

</div>
</div>
<a id="a80306f9557f50f930ca86426af1bd922" name="a80306f9557f50f930ca86426af1bd922"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80306f9557f50f930ca86426af1bd922">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Union[
        Tuple[List[pytorch.Tensor], pytorch.Tensor],
        Tuple[pytorch.Tensor, pytorch.Tensor],
    ] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">pytorch.Tensor
    &#160;</td>
          <td class="paramname"><em>x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The forwards method of the nn.Module. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>pytorch.Tensor: The model input. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Union[ Tuple[List[pytorch.Tensor], pytorch.Tensor], Tuple[pytorch.Tensor, pytorch.Tensor], ]: The tuple of actor and critic outputs. </dd></dl>

<p>Reimplemented from <a class="el" href="classrlpack_1_1utils_1_1base_1_1model_1_1_model.html#abeb2e8825db08f887f66a7077f9504f4">rlpack.utils.base.model.Model</a>.</p>

</div>
</div>
<a id="ad3ef71ea9ad689862d614e2e2b836380" name="ad3ef71ea9ad689862d614e2e2b836380"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3ef71ea9ad689862d614e2e2b836380">&#9670;&#160;</a></span>get_actor_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[pytorch.Tensor] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.get_actor_parameters </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtains the parameters for actor model. </p>
<dl class="section return"><dt>Returns</dt><dd>: List[pytorch.Tensor]: The list of parameters for actor. </dd></dl>

</div>
</div>
<a id="a31a2e5d527024e54a7756530ea9d610c" name="a31a2e5d527024e54a7756530ea9d610c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31a2e5d527024e54a7756530ea9d610c">&#9670;&#160;</a></span>get_critic_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[pytorch.Tensor] rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.get_critic_parameters </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtains the parameters for critic model. </p>
<dl class="section return"><dt>Returns</dt><dd>: List[pytorch.Tensor]: The list of parameters for critic. </dd></dl>

</div>
</div>
<a id="a87c537f8dca13dac12dd9455e4e460ef" name="a87c537f8dca13dac12dd9455e4e460ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87c537f8dca13dac12dd9455e4e460ef">&#9670;&#160;</a></span>get_noise()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> pytorch.Tensor rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.get_noise </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>at</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtains the noise from <code><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html#a01b4d6aed4ff2f512c855d7c05978630" title="The noise values for each timestep.">ActorCriticMlpPolicy._noise</a></code> list. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">at</td><td>int: Index from which we wish to retrieve the noise from noise list. By default, retrieves the last noise tensor. Default: -1 </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>: pytorch.Tensor: The noise tensor. </dd></dl>

</div>
</div>
<h2 class="groupheader">Field Documentation</h2>
<a id="a1cad5fd5a8276af751e4f1c2ac0c0e2c" name="a1cad5fd5a8276af751e4f1c2ac0c0e2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cad5fd5a8276af751e4f1c2ac0c0e2c">&#9670;&#160;</a></span>_action_space_dim</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._action_space_dim</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The output action space dimension as per given <code>action_space</code>. </p>

</div>
</div>
<a id="a58257bfa075de917a381c1277ed20ab5" name="a58257bfa075de917a381c1277ed20ab5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58257bfa075de917a381c1277ed20ab5">&#9670;&#160;</a></span>_activations</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._activations</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The activations from input <code>activation</code>. </p>

</div>
</div>
<a id="a740735217565959d556dc9df577e5eee" name="a740735217565959d556dc9df577e5eee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a740735217565959d556dc9df577e5eee">&#9670;&#160;</a></span>_apply_actor_activation</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._apply_actor_activation</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Flag indicating whether to apply activation to output of actor head or not. </p>

</div>
</div>
<a id="a424acbf7bc0cd03e9cb230c64cc76bde" name="a424acbf7bc0cd03e9cb230c64cc76bde"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a424acbf7bc0cd03e9cb230c64cc76bde">&#9670;&#160;</a></span>_apply_critic_activation</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._apply_critic_activation</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Flag indicating whether to apply activation to output of critic head or not. </p>

</div>
</div>
<a id="a01b4d6aed4ff2f512c855d7c05978630" name="a01b4d6aed4ff2f512c855d7c05978630"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01b4d6aed4ff2f512c855d7c05978630">&#9670;&#160;</a></span>_noise</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy._noise</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The noise values for each timestep. </p>

</div>
</div>
<a id="aa5cf6dc54f85cb7adb659dcef3cf6302" name="aa5cf6dc54f85cb7adb659dcef3cf6302"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5cf6dc54f85cb7adb659dcef3cf6302">&#9670;&#160;</a></span>actor_feature_extractor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.actor_feature_extractor</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The feature extractor for actor model. </p>
<p >This will always be None if network is shared. </p>

</div>
</div>
<a id="aeccac34c455d3068c34a4cde629e7d85" name="aeccac34c455d3068c34a4cde629e7d85"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeccac34c455d3068c34a4cde629e7d85">&#9670;&#160;</a></span>actor_head</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.actor_head</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The final head for actor; creates logits/parameters for actions. </p>

</div>
</div>
<a id="a077ad80c1325b346324d336ac836cc81" name="a077ad80c1325b346324d336ac836cc81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a077ad80c1325b346324d336ac836cc81">&#9670;&#160;</a></span>actor_projector</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.actor_projector</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The projection vector for actor. </p>
<p >This will be None if <code>use_actor_projection</code> is False. </p>

</div>
</div>
<a id="aa41057f745afd80c3c64913d4a7e9806" name="aa41057f745afd80c3c64913d4a7e9806"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa41057f745afd80c3c64913d4a7e9806">&#9670;&#160;</a></span>critic_feature_extractor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.critic_feature_extractor</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The feature extractor for critic model. </p>
<p >This will always be None if network is shared. </p>

</div>
</div>
<a id="a20b1b9443191489e94af5b586d6fae8f" name="a20b1b9443191489e94af5b586d6fae8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20b1b9443191489e94af5b586d6fae8f">&#9670;&#160;</a></span>critic_head</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.critic_head</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The final head for critic; creates the state value. </p>

</div>
</div>
<a id="a815a4185be1c351bf7f0e40b26c01749" name="a815a4185be1c351bf7f0e40b26c01749"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a815a4185be1c351bf7f0e40b26c01749">&#9670;&#160;</a></span>dropout</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.dropout</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input dropout probability. </p>

</div>
</div>
<a id="a5abaab59fd00400a6fcaaba533fbd201" name="a5abaab59fd00400a6fcaaba533fbd201"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5abaab59fd00400a6fcaaba533fbd201">&#9670;&#160;</a></span>exploration_tool</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.exploration_tool</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>exploration_tool</code>. </p>

</div>
</div>
<a id="abc989aeb5a2c083821bf19604501f507" name="abc989aeb5a2c083821bf19604501f507"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc989aeb5a2c083821bf19604501f507">&#9670;&#160;</a></span>flatten</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.flatten</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The object to flatten the output fo feature extractor. </p>

</div>
</div>
<a id="a9be4039f8ff54b6045b8e50a0999fbfb" name="a9be4039f8ff54b6045b8e50a0999fbfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9be4039f8ff54b6045b8e50a0999fbfb">&#9670;&#160;</a></span>has_exploration_tool</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.has_exploration_tool</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Flag indicating whether to Model has exploration tool. </p>

</div>
</div>
<a id="acb05c340b3bf2f6693382040abbda5d3" name="acb05c340b3bf2f6693382040abbda5d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb05c340b3bf2f6693382040abbda5d3">&#9670;&#160;</a></span>mlp_feature_extractor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.mlp_feature_extractor</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The feature extractor instance of rlpack.models._mlp_feature_extractor.MlpFeatureExtractor. </p>
<p >This will be None if network is not shared. </p>

</div>
</div>
<a id="aecf9f6171326ea4e102b94f500ec83bc" name="aecf9f6171326ea4e102b94f500ec83bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecf9f6171326ea4e102b94f500ec83bc">&#9670;&#160;</a></span>share_network</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.share_network</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>share_network</code>. </p>

</div>
</div>
<a id="acc3d0c82767c3101f50c0dd71b9a6e42" name="acc3d0c82767c3101f50c0dd71b9a6e42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc3d0c82767c3101f50c0dd71b9a6e42">&#9670;&#160;</a></span>use_actor_projection</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.use_actor_projection</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>use_actor_projection</code>. </p>

</div>
</div>
<a id="a812806819ae4b98740be3dc7f17607f3" name="a812806819ae4b98740be3dc7f17607f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a812806819ae4b98740be3dc7f17607f3">&#9670;&#160;</a></span>use_diagonal_embedding_on_projection</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">rlpack.models.actor_critic_mlp_policy.ActorCriticMlpPolicy.use_diagonal_embedding_on_projection</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The input <code>use_diagonal_embedding_on_projection</code>. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacerlpack.html">rlpack</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1models.html">models</a></li><li class="navelem"><a class="el" href="namespacerlpack_1_1models_1_1actor__critic__mlp__policy.html">actor_critic_mlp_policy</a></li><li class="navelem"><a class="el" href="classrlpack_1_1models_1_1actor__critic__mlp__policy_1_1_actor_critic_mlp_policy.html">ActorCriticMlpPolicy</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
